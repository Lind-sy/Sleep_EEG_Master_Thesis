{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Copy of LSTMCNN_v3.ipynb","version":"0.3.2","provenance":[{"file_id":"1U8jImiujKy5Vq1SV9OLsKdacQP2idZW4","timestamp":1552683718911},{"file_id":"https://github.com/Lind-sy/EEG_Sleep/blob/master/LSTMCNN_v3.ipynb","timestamp":1550507923411}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"er2f1JFBLF1p","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aDozSgIceRAj","colab_type":"code","colab":{}},"source":["!pip install pyedflib\n","!pip install git+https://github.com/EtienneCmb/visbrain\n","!pip install beautifultable"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iO21Ns_2e_q6","colab_type":"code","outputId":"4d04cb34-6886-409d-aeca-56a7ba6d3b18","executionInfo":{"status":"ok","timestamp":1558716127150,"user_tz":-180,"elapsed":2373,"user":{"displayName":"Linda Kalašņikova","photoUrl":"","userId":"06739455726453495049"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import visbrain as vb\n","#from visbrain.io import write_fig_hyp, read_hypno\n","import pandas as pd\n","import pyedflib as edf\n","import matplotlib.pyplot as plt \n","import glob\n","import numpy as np\n","import os\n","import keras\n","import keras.backend as K\n","from keras.layers import LSTM,Dropout,Dense,TimeDistributed,Conv1D,MaxPooling1D,Flatten\n","import tensorflow as tf\n","from IPython.display import display\n","import warnings\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import Sequential\n","from keras import losses\n","from keras import losses\n","from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n","    concatenate, SpatialDropout1D, TimeDistributed, Bidirectional, LSTM\n","from keras import optimizers, losses, activations, models\n","import time\n","import matplotlib\n","import beautifultable\n","from sklearn.metrics import mean_squared_error, confusion_matrix, accuracy_score, f1_score\n","from beautifultable import BeautifulTable\n","from keras.utils.np_utils import to_categorical\n","from keras.layers import BatchNormalization\n","\n","warnings.filterwarnings(\"ignore\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-ncBwRV0eNIp","colab_type":"code","colab":{}},"source":["def retrieveHypnogramData(path_to_hypno, path_to_datafile):\n","    grid = True     # display the grid\n","    ascolor = True  # plt as color or in black and white\n","    file = None     # Name of the file to be saved example : 'myfile.png'\n","    data, sf = read_hypno(path_to_hypno,datafile=path_to_datafile)\n","    print(len(data))\n","    print(sf)\n","    write_fig_hyp(data, 1, grid=grid, ascolor=ascolor, file=file)\n","    return data,sf\n","\n","def retrieveHypnogramData_2v(path_to_hypno, path_to_datafile):\n","    data, sf = read_hypno(path_to_hypno,datafile=path_to_datafile)\n","    return data,sf\n","\n","def seperateSignalsFromEDF(datafile):\n","    d = edf.EdfReader(datafile)\n","    n = 2\n","    eegSignals = pd.DataFrame(columns=[['Signal']],index=range(n))\n","    if n != 0:\n","        for i in np.arange(n):\n","            sigbuf= d.readSignal(i)\n","            print(d.getSignalLabels())\n","            eegSignals.loc[i].Signal=[sigbuf]\n","    d._close()\n","    del d\n","    return eegSignals\n","\n","def divideSignalInSleepStages(sleep_stages,sleep_signal):\n","    chunks = len(sleep_signal)//len(sleep_stages)\n","    step = 0\n","    nextStep = int(step+chunks)\n","    data_set = pd.DataFrame(columns=[['Class','Signal']],index=range(len(sleep_stages)-1))\n","    for i in range(len(sleep_stages)-1):\n","        subsignal = sleep_signal[step:nextStep]\n","        step = nextStep\n","        nextStep=step+chunks\n","        signal_with_stage = np.array(subsignal)\n","        data_set.loc[i].Class = int(sleep_stages[i])\n","        data_set.loc[i].Signal=[signal_with_stage]\n","    return data_set\n","\n","def plot_Signal(eegSignals, n):\n","    signal = get_signal(eegSignals,n)\n","    #print(signal.shape)\n","    #plt.plot(signal)\n","    #plt.xlabel('Time [samples]')\n","    #plt.ylabel('Amplitude')\n","    #plt.grid(True)\n","    #plt.show()\n","    \n","def get_signal(data_set,n):\n","    eegSignal = data_set.iloc[n]['Signal']\n","    signal = eegSignal[0]\n","    return signal\n","  \n","def getChannelData(file_list, data):\n","    eegSignals = []\n","    for datafile in file_list:\n","        eegSignals = seperateSignalsFromEDF(datafile)\n","    plot_Signal(eegSignals,1)\n","    #devide data into classes\n","    signal_data1 = pd.DataFrame(columns=[['Class','Signal']])\n","    signal_data2 = pd.DataFrame(columns=[['Class','Signal']])\n","    for i in range(2):\n","        sigbuf = get_signal(eegSignals,i)\n","        data_set = divideSignalInSleepStages(data, sigbuf)\n","        if i == 0:\n","            signal_data1 = data_set\n","        else:\n","            signal_data2 = data_set\n","    return signal_data1,signal_data2\n","  \n","def keras_auc(y_true, y_pred):\n","    auc = tf.metrics.auc(y_true, y_pred)[1]\n","    K.get_session().run(tf.local_variables_initializer())\n","    return auc\n","\n","def data_generation2(signal_data1, signal_data2, batch_size, expand_dim=True,dim_shape = (1,500,2)):\n","    # Initialization\n","    #X = np.empty((self.dim))\n","    y = np.empty((batch_size), dtype=int)\n","    #s = self.dataSet.iloc[0]['Signal']\n","    chunk = dim_shape[1]\n","    parts = int(3000 / dim_shape[1])\n","    a = np.empty([batch_size, dim_shape[2], dim_shape[1]])\n","    # Generate data\n","    k=0\n","    for i in range(len(signal_data2)-1):\n","        s1 = signal_data1.iloc[i]['Signal']\n","        s2 = signal_data2.iloc[i]['Signal']\n","        cl = signal_data1.iloc[i]['Class']\n","        stepOne = 0\n","        sign = s1[0]\n","        sign2 = s2[0]\n","        clas1 = cl[0]\n","        for j in range(parts):\n","            a[k, :] = np.array([sign[stepOne:(stepOne + chunk)], sign2[stepOne:(stepOne + chunk)]])\n","            stepOne = stepOne + chunk\n","            y[k] = clas1\n","            k = k+1\n","    w = a\n","    a_new = np.reshape(w, (w.shape[0], w.shape[2], 2))\n","    #output shape(32, 1, 500, 2)\n","    if(expand_dim):\n","      a_new = np.expand_dims(a_new, axis=1)\n","    X = a_new\n","    print(X.shape)\n","    return X, y\n","  \n","def data_generation_sleep(signal_data1, signal_data2, batch_size, expand_dim=True,dim_shape = (1,500,2)):\n","    # Initialization\n","    #X = np.empty((self.dim))\n","    y = np.empty((batch_size), dtype=int)\n","    #s = self.dataSet.iloc[0]['Signal']\n","    chunk = dim_shape[1]\n","    parts = int(3000 / dim_shape[1])\n","    a = np.empty([batch_size, dim_shape[2], dim_shape[1]])\n","    # Generate data\n","    k=0\n","    nomoda  = 0\n","    for i in range(len(signal_data2)-1):\n","        s1 = signal_data1.iloc[i]['Signal']\n","        s2 = signal_data2.iloc[i]['Signal']\n","        cl = signal_data1.iloc[i]['Class']\n","        stepOne = 0\n","        sign = s1[0]\n","        sign2 = s2[0]\n","        clas1 = cl[0]\n","        \n","        if (clas1 >= 1) and (clas1 <= 4):\n","          clas1 = 1\n","          \n","        if (clas1<=0) or (clas1 > 4):\n","          clas1 = 0\n","\n","        for j in range(parts):\n","          a[k, :] = np.array([sign[stepOne:(stepOne + chunk)], sign2[stepOne:(stepOne + chunk)]])\n","          stepOne = stepOne + chunk\n","          y[k] = clas1\n","          k = k+1\n","            #print(clas1)\n","    w = a\n","    a_new = np.reshape(w, (w.shape[0], w.shape[2], 2))\n","    #output shape(32, 1, 500, 2)\n","    if(expand_dim):\n","      a_new = np.expand_dims(a_new, axis=1)\n","    X = a_new\n","    print(X.shape)\n","    #print(y)\n","    \n","    y[y>4]=0\n","    y[y<0]=0\n","  \n","    return X,keras.utils.to_categorical(y)\n","  \n","def prepare_data_sleep(expand_dim=True,data_shape = (1,500,2)):\n","    signal_data1 = pd.DataFrame(columns=[['Class', 'Signal']])\n","    signal_data2 = pd.DataFrame(columns=[['Class', 'Signal']])\n","\n","    hypnogram_files = [x for x in os.listdir('/content/gdrive/My Drive/EEG/Test') if\n","                       x.endswith(\"gram.edf\")]\n","    eeg_files = [x for x in os.listdir('/content/gdrive/My Drive/EEG/Test') if\n","                 x.endswith(\"PSG.edf\")]\n","    hypnogram_files.sort()\n","    eeg_files.sort()\n","    for i in range(1):\n","        hip_fil = '/content/gdrive/My Drive/EEG/Test/SC4001EC-Hypnogram.edf' \n","        eeg_fil = '/content/gdrive/My Drive/EEG/Test/SC4001E0-PSG.edf'\n","        data, sf = retrieveHypnogramData_2v(hip_fil, eeg_fil)\n","        sig_data1, sig_data2 = getChannelData([eeg_fil], data)\n","        frames = [signal_data1, sig_data1]\n","        signal_data1 = pd.concat(frames)\n","        frames2 = [signal_data2, sig_data2]\n","        signal_data2 = pd.concat(frames2)\n","    X,y = data_generation_sleep(signal_data1, signal_data2, len(signal_data2)*6,expand_dim, dim_shape = data_shape)\n"," \n","    return X,y  \n","\n","\n","def prepare_data(expand_dim=True,data_shape = (1,500,2)):\n","    signal_data1 = pd.DataFrame(columns=[['Class', 'Signal']])\n","    signal_data2 = pd.DataFrame(columns=[['Class', 'Signal']])\n","\n","    hypnogram_files = [x for x in os.listdir('/content/gdrive/My Drive/EEG/Test') if\n","                       x.endswith(\"gram.edf\")]\n","    eeg_files = [x for x in os.listdir('/content/gdrive/My Drive/EEG/Test') if\n","                 x.endswith(\"PSG.edf\")]\n","    hypnogram_files.sort()\n","    eeg_files.sort()\n","    for i in range(1):\n","        hip_fil = '/content/gdrive/My Drive/EEG/Test/SC4001EC-Hypnogram.edf' \n","        eeg_fil = '/content/gdrive/My Drive/EEG/Test/SC4001E0-PSG.edf'\n","        data, sf = retrieveHypnogramData_2v(hip_fil, eeg_fil)\n","        sig_data1, sig_data2 = getChannelData([eeg_fil], data)\n","        frames = [signal_data1, sig_data1]\n","        signal_data1 = pd.concat(frames)\n","        frames2 = [signal_data2, sig_data2]\n","        signal_data2 = pd.concat(frames2)\n","    X,y = data_generation2(signal_data1, signal_data2, len(signal_data2)*6,expand_dim, dim_shape = data_shape)\n","    return X,y\n","    \n","def plot_hypnogram(stages, labels=None, title='', ax1=None, **kwargs):\n","    if labels is None:\n","        if np.max(stages)==4:\n","            print('assuming 0=W, 1=S1, 2=S2, 3=SWS, 4=REM')\n","            labels = ['W', 'S1', 'S2', 'SWS', 'REM']\n","        if np.max(stages)==5:\n","            print('assuming 0=W, 1=S1, 2=S2, 3=S3, 4=S4, 5=SWS')\n","            labels = ['W', 'S1', 'S2', 'S3', 'S4', 'REM']\n","        if np.max(stages)==8:\n","            print('assuming 0=W, 1=S1, 2=S2, 3=S3, 4=S4, 5=SWS')\n","            labels = ['W', 'S1', 'S2', 'S3', 'S4', 'REM', 'Movement']\n","    labels_dict = dict(zip(np.arange(len(labels)),labels))\n","\n","    x = []\n","    y = []\n","    for i in np.arange(len(stages)):\n","        s = stages[i]\n","        if labels_dict[s]=='W':   p = -0\n","        if labels_dict[s]=='REM': p = -1\n","        if labels_dict[s]=='S1':  p = -2\n","        if labels_dict[s]=='S2':  p = -3\n","        if labels_dict[s]=='SWS': p = -4\n","        if labels_dict[s]=='S3': p = -4\n","        if labels_dict[s]=='S4': p = -5\n","        if i!=0:\n","            y.append(p)\n","            x.append(i-1)   \n","        y.append(p)\n","        x.append(i)\n","        \n","    x = np.array(x)*30\n","    y = np.array(y)\n","    if ax1 is None:\n","        fig = plt.figure(figsize=[8,2])\n","        ax1 = fig.add_subplot(111)\n","    formatter = matplotlib.ticker.FuncFormatter(lambda s, x: time.strftime('%H:%M', time.gmtime(s)))\n","    ax1.xaxis.set_major_formatter(formatter)\n","    ax1.plot(x,y, **kwargs)\n","    plt.yticks([0,-1,-2,-3,-4,-5], ['Nomoda','REM', 'N1', 'N2', 'N3' ])\n","    plt.xticks(np.arange(0,x[-1],3600))#3600\n","    plt.xlabel('Laiks')\n","    plt.ylabel('Miega stadijas')\n","    plt.title(title)\n","    plt.tight_layout()\n","\n","def my_predict(model, data, TL, classes = True):\n","    wake = 0; s1 = 1; s2 = 2; sws = 3; rem = 4\n","    mapping = {0:wake, 1:s1, 2:s2, 3:sws, 4:rem}\n","    cnn_preds = model.predict(data)\n","    scores = model.evaluate(data, TL, verbose=0)\n","    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","    preds = np.roll(cnn_preds,-4, axis=0)\n","    if classes:\n","        preds = np.argmax(preds,1)\n","        preds = [mapping[x] for x in preds]\n","    return preds\n","  \n","def my_predict_sleep(model, data, TL, classes = True):\n","    wake = 0; s1 = 1;\n","    mapping = {0:wake, 1:s1}\n","    cnn_preds = model.predict(data)\n","    scores = model.evaluate(data, TL, verbose=0)\n","    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","    preds = np.roll(cnn_preds,-2, axis=0)\n","    #print(preds)\n","    if classes:\n","        preds = np.argmax(preds,1)\n","        preds = [mapping[x] for x in preds]\n","    return preds\n","  \n","def show_sample_hypnogram(filename, start=None,stop=None, title='True Sleep Stage'):\n","    hypno = np.loadtxt(filename)\n","    hypno = hypno[start:stop]\n","    print(hypno)\n","    plot_hypnogram(hypno,title = title)\n","    \n","def getStageTrainingAndValidationData(signal_data1,signal_data2,classOfSamples,traingSize,testSize,validationSize):\n","    eeg_test = pd.DataFrame(columns=[['Class', 'Signal']])\n","    eeg_val = pd.DataFrame(columns=[['Class', 'Signal']])\n","    eeg_train = pd.DataFrame(columns=[['Class', 'Signal']])\n","    temp = pd.DataFrame(columns=[['Class', 'Signal']], index=range(1))\n","    #k = 0\n","    for i in range(len(signal_data1)- 1):\n","        clas = signal_data1.iloc[i]['Class']\n","        sig = signal_data1.iloc[i]['Signal']\n","        sig2 = signal_data2.iloc[i]['Signal']\n","        temp.loc[0].Class = clas[0]\n","        temp.loc[0].Signal = [[sig[0], sig2[0]]]\n","        if clas[0] == classOfSamples:\n","            #k = 1+k\n","            if len(eeg_test)<testSize:\n","                frames = [eeg_test, temp]\n","                eeg_test = pd.concat(frames)\n","            elif len(eeg_val)<validationSize:\n","                frame = [eeg_val, temp]\n","                eeg_val = pd.concat(frame)\n","            elif len(eeg_train)<traingSize:\n","                frames = [eeg_train, temp]\n","                eeg_train = pd.concat(frames)\n","    #print(k)\n","    return eeg_train,eeg_test,eeg_val\n","  \n","def getSleepStageTrainingAndValidationData(signal_data1,signal_data2,traingSize,testSize,validationSize):\n","    eeg_test = pd.DataFrame(columns=[['Class', 'Signal']])\n","    eeg_val = pd.DataFrame(columns=[['Class', 'Signal']])\n","    eeg_train = pd.DataFrame(columns=[['Class', 'Signal']])\n","    temp = pd.DataFrame(columns=[['Class', 'Signal']], index=range(1))\n","    #k = 0\n","    for i in range(len(signal_data1)- 1):\n","        clas = signal_data1.iloc[i]['Class']\n","        sig = signal_data1.iloc[i]['Signal']\n","        sig2 = signal_data2.iloc[i]['Signal']\n","        temp.loc[0].Class = clas[0]\n","        temp.loc[0].Signal = [[sig[0], sig2[0]]]\n","        if clas[0] != 0:\n","            temp.loc[0].Class = 1\n","            if len(eeg_test)<testSize:\n","                frames = [eeg_test, temp]\n","                eeg_test = pd.concat(frames)\n","            elif len(eeg_val)<validationSize:\n","                frame = [eeg_val, temp]\n","                eeg_val = pd.concat(frame)\n","            elif len(eeg_train)<traingSize:\n","                frames = [eeg_train, temp]\n","                eeg_train = pd.concat(frames)\n","        \n","    return eeg_train,eeg_test,eeg_val  \n","  \n","def predict_eeg_signal_sleep(model,filename,clases,expand_dim=True, dat_shape = (1,500,2)):\n","  data2,y_labels = prepare_data_sleep(expand_dim, data_shape =dat_shape )\n","  #y_labels[y_labels>4]=0\n","  #y_labels[y_labels<0]=0\n","  \n","  #print(y_labels.size)\n","  #TL2 = keras.utils.to_categorical(y_labels, num_classes=clases)\n","  #filename = 'sample_test_hypnogram_CNN'\n","  hypnograms = True\n","  print('Predicting...')\n","  preds1 = my_predict_sleep(model, data2,y_labels,classes=True)\n","  #np.savetxt(filename + '.csv', preds1, fmt='%d')\n","  #print('Predictions saved to {}'.format (filename + '.csv'))\n","  #if hypnograms:\n","  #    plot_hypnogram(preds1, title ='Predictions for {}'.format(os.path.basename(filename)))\n","  #    plt.savefig(filename + '.hyp.png')\n","  #    print('Hynograms saved to {}'.format(filename + '.hyp.png'))\n","  return y_labels, preds1  \n","  \n","def predict_eeg_signal(model,filename,clases,expand_dim=True, dat_shape = (1,500,2)):\n","  data2,y_labels = prepare_data(expand_dim, data_shape =dat_shape )\n","  y_labels[y_labels>4]=0\n","  y_labels[y_labels<0]=0\n","  \n","  \n","  print(y_labels)\n","  TL2 = keras.utils.to_categorical(y_labels, num_classes=clases)\n","  #filename = 'sample_test_hypnogram_CNN'\n","  hypnograms = True\n","  print('Predicting...')\n","  preds1 = my_predict(model, data2,TL2,classes=True)\n","  np.savetxt(filename + '.csv', preds1, fmt='%d')\n","  print('Predictions saved to {}'.format (filename + '.csv'))\n","  if hypnograms:\n","      plot_hypnogram(preds1, title ='Predictions for {}'.format(os.path.basename(filename)))\n","      plt.savefig(filename + '.hyp.png')\n","      print('Hynograms saved to {}'.format(filename + '.hyp.png'))\n","  return y_labels, preds1\n","\n","def plot_original_eeg(filename,expand_dim=True, dat_shape = (1,500,2)):\n","  hypnograms = True\n","  data2,y_labels = prepare_data(data_shape =dat_shape)\n","  y_labels[y_labels>4]=0\n","  np.savetxt(filename + '.csv', y_labels, fmt='%d')\n","  print('Predictions saved to {}'.format (filename + '.csv'))\n","  if hypnograms:\n","      plot_hypnogram(y_labels, title ='Original signal for {}'.format(os.path.basename(filename)))\n","      plt.savefig(filename + '.hyp.png')\n","      print('Hynograms saved to {}'.format(filename + '.hyp.png'))\n","      \n","def train_model(model, dataSet,validDataSet,weights_name, epochs, batch_size, weight_loaded = False,expand = True, verbose = True,dim_shape = (64,500,2)):\n","  if(weight_loaded):\n","    model.load_weights(weights_name)\n","\n","  list_of_indexes = np.arange(0,dataSet.shape[0],1)\n","  labels = dataSet['Class'].values.tolist()\n","  list_of_val_index = np.arange(0,validDataSet.shape[0],1)\n","  labels_val = validDataSet['Class'].values.tolist()\n","\n","  tra_generator = MyDatGen(list_of_Indexes=list_of_indexes,batch_size=batch_size ,dataSet=dataSet,labels=labels, expand_dim = expand, dim =dim_shape)\n","  val_generator = MyDatGen(list_of_Indexes=list_of_val_index,batch_size=batch_size,dataSet=validDataSet,labels=labels_val, expand_dim = expand,dim =dim_shape)\n","  checkpointer = ModelCheckpoint(filepath = weights_name, verbose = 1, save_best_only = False)\n","  hist = model.fit_generator(epochs = epochs, generator=tra_generator,validation_data=val_generator,use_multiprocessing=True,workers=0)\n","  model.save_weights(weights_name)\n","  \n","  \n","def generateSleepWakeDataSet(signal_data1,signal_data2):\n","  stageSleep, sleep_test, sleep_val = getSleepStageTrainingAndValidationData(signal_data1,signal_data2,500,50,107)\n","  awake,awake_test,awake_val = getStageTrainingAndValidationData(signal_data1,signal_data2,0,500,50,107)\n","  \n","  frames = [awake, stageSleep]\n","  dataSet = pd.concat(frames)\n","\n","  frames1 = [awake_test, sleep_test]\n","  testDataSet = pd.concat(frames1)\n","\n","  frames2 = [awake_val, sleep_val]\n","  validDataSet = pd.concat(frames2)\n","  return dataSet, testDataSet, validDataSet\n","  \n","def generateDataSets(signal_data1,signal_data2): \n","  signal_data2= signal_data2.sample(frac=1)\n","  signal_data1 = signal_data1.sample(frac=1)\n","  awake,awake_test,awake_val = getStageTrainingAndValidationData(signal_data1,signal_data2,0,500,50,107) \n","  rem, rem_test, rem_val = getStageTrainingAndValidationData(signal_data1,signal_data2,4,500,50,107)\n","  stageSleep1, sleep_test1, sleep_val1 = getStageTrainingAndValidationData(signal_data1,signal_data2,1,500,50,100)\n","  stageSleep2, sleep_test2, sleep_val2 = getStageTrainingAndValidationData(signal_data1,signal_data2,2,500,50,100)\n","  stageSleep3, sleep_test3, sleep_val3 = getStageTrainingAndValidationData(signal_data1,signal_data2,3,500,50,100)\n","\n","  frames = [awake, rem, stageSleep1, stageSleep2, stageSleep3]\n","  dataSet = pd.concat(frames)\n","\n","  frames1 = [awake_test, rem_test,sleep_test1,sleep_test2,sleep_test3]\n","  testDataSet = pd.concat(frames1)\n","\n","  frames2 = [awake_val,rem, sleep_val1,sleep_val2,sleep_val3]\n","  validDataSet = pd.concat(frames2)\n","  return dataSet, testDataSet, validDataSet\n","\n","def getFirstLastIndex(sizeStep, len_shape):\n","  data2,y_labels = prepare_data(data_shape =(1,sizeStep,2))\n","  y_labels[y_labels>4]=0\n","  res = next(x for x, val in enumerate(y_labels[:len_shape]) if val > 0) \n","  res2 = next(x for x, val in enumerate(reversed(y_labels[:len_shape])) if val > 0) \n","  res2 = res+res2\n","  \n","  if n_length == 1000:\n","    res2 = res2-5\n","  elif n_length == 3000:\n","    res2 = res2-165\n","  else:\n","    res2 = res2-1000\n","  \n","  return res-10,res2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SK_s7Z0heNI-","colab_type":"code","outputId":"d50a939b-a987-4a8e-99a1-dbbaa0610d24","executionInfo":{"status":"ok","timestamp":1558716197612,"user_tz":-180,"elapsed":56761,"user":{"displayName":"Linda Kalašņikova","photoUrl":"","userId":"06739455726453495049"}},"colab":{"base_uri":"https://localhost:8080/","height":337}},"source":["signal_data1 = pd.DataFrame(columns=[['Class','Signal']])\n","signal_data2 = pd.DataFrame(columns=[['Class','Signal']])\n","    \n","hypnogram_files = [x for x in os.listdir('/content/gdrive/My Drive/EEG/Test') if x.endswith(\"gram.edf\")]\n","eeg_files = [x for x in os.listdir('/content/gdrive/My Drive/EEG/Test') if x.endswith(\"PSG.edf\")]\n","\n","print(hypnogram_files.sort())\n","print(eeg_files.sort())\n","\n","for i in range(0,7,1):\n","    hip_fil ='/content/gdrive/My Drive/EEG/Test/'+hypnogram_files[i]\n","    eeg_fil ='/content/gdrive/My Drive/EEG/Test/'+eeg_files[i]\n","    data,sf = retrieveHypnogramData_2v(hip_fil,eeg_fil)\n","    sig_data1,sig_data2 = getChannelData([eeg_fil], data)\n","    frames = [signal_data1, sig_data1]\n","    signal_data1 = pd.concat(frames)\n","    frames2 = [signal_data2, sig_data2]\n","    signal_data2 = pd.concat(frames2)\n","    \n","    \n","print(signal_data1.shape)\n","print(signal_data2.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["None\n","None\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","(19505, 2)\n","(19505, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3tca0mz-eNJS","colab_type":"code","colab":{}},"source":["#'Generates data for Keras'\n","class MyDatGen(keras.utils.Sequence):\n","    def __init__(self, list_of_Indexes, dataSet, labels, batch_size=64, dim=(64,1000,2), n_channels=1,\n","                 n_classes=2, shuffle=True,expand_dim=True):\n","        'Initialization'\n","        self.dim = dim\n","        self.batch_size = batch_size\n","        self.labels = labels\n","        self.list_of_Indexes = list_of_Indexes\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.dataSet = dataSet\n","        self.shuffle = shuffle\n","        self.expand_dim = expand_dim\n","        self.on_epoch_end()\n","        \n","#'Denotes the number of batches per epoch'\n","    def __len__(self):      \n","        return int(np.floor(len(self.list_of_Indexes) / self.batch_size))\n","    # 'Generate one batch of data'\n","    def __getitem__(self, index):\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","        # Find list of IDs\n","        list_IDs_temp = [self.list_of_Indexes[k] for k in indexes]\n","        # Generate data\n","        X, y = self.__data_generation(list_IDs_temp)\n","\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_of_Indexes))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, list_indexes_temp):\n","        # Initialization\n","        #X = np.empty((self.dim))\n","        y = np.empty((self.batch_size), dtype=int)\n","        #s = self.dataSet.iloc[0]['Signal']\n","        chunk = self.dim[1]\n","        parts = int(3000/self.dim[1])\n","        k = 0\n","        a = np.empty([self.batch_size,self.dim[2],self.dim[1]])\n","        # Generate data\n","        for i, ID in enumerate(list_indexes_temp):\n","            stepOne = 0\n","            cl = self.dataSet.iloc[ID]['Class']\n","            sig = self.dataSet.iloc[ID]['Signal']\n","            si = sig[0]; sign = si[0]; sign2 = si[1]; clas = cl[0]\n","            for j in range(parts):\n","                if k!=self.batch_size:\n","                    a[k,:] = np.array([sign[stepOne:(stepOne+chunk)],sign2[stepOne:(stepOne+chunk)]])\n","                    stepOne = stepOne+chunk\n","                    y[k] = clas\n","                    k = k+1\n","                else:\n","                    break\n","        w = a\n","        a_new = np.reshape(w,(w.shape[0],w.shape[2],2))\n","        \n","        if(self.expand_dim):\n","          a_new = np.expand_dims(a_new, axis=1)\n","          \n","        X = a_new\n","        return X, to_categorical(y)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ijv70PexFoP","colab_type":"code","colab":{}},"source":["def get_lstm_network(n_length, n_signals):\n","  print('********************************************LSTM Arhitecture***************************************************')\n","  model = Sequential()\n","  model.add(LSTM(256,input_shape=(n_length, n_signals), return_sequences=True)) #should be 1000X2 signal shape \n","  model.add(LSTM(256))\n","  model.add(Dense(n_outputs, activation='sigmoid'))\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  return model \n","\n","def get_lstm_cnn2(n_steps,n_length,n_signals):\n","  print('********************************************CNN(2 layer) + LSTM Arhitecture***************************************************')\n","\n","  model = Sequential()\n","\n","  model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'),\n","                            input_shape=(n_steps,n_length,n_signals)))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(Dropout(0.5)))\n","  model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n","  model.add(TimeDistributed(Flatten()))\n","  model.add(LSTM(100))\n","  model.add(Dense(100, activation='relu'))\n","  model.add(Dense(n_outputs, activation='sigmoid'))\n","\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[keras_auc])\n","  return model\n","\n","def get_cnn_8layer(n_length,n_signals):\n","  print('********************************************CNN Arhitecture***************************************************')\n","  model = Sequential()\n","\n","  model.add(Convolution1D(filters=16, kernel_size=3, activation='relu',input_shape=(n_length,n_signals)))\n","  model.add(BatchNormalization())\n","  model.add(Convolution1D(filters=16, kernel_size=3, activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling1D(pool_size=2))\n","  model.add(SpatialDropout1D(rate = 0.01))\n","\n","  model.add(Convolution1D(filters=32, kernel_size=3, activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(Convolution1D(filters=32, kernel_size=3, activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling1D(pool_size=2))\n","  model.add(SpatialDropout1D(rate = 0.01))\n","\n","  model.add(Convolution1D(filters=32, kernel_size=3, activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(Convolution1D(filters=32, kernel_size=3, activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling1D(pool_size=2))\n","  model.add(SpatialDropout1D(rate = 0.01))\n","\n","  model.add(Convolution1D(filters=256, kernel_size=3, activation='relu'))\n","  model.add(BatchNormalization()) \n","  model.add(Convolution1D(filters=256, kernel_size=3, activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling1D(pool_size=2))\n","\n","  model.add(Flatten())\n","  model.add(Dropout(0.5))\n","  model.add(Dense(64, activation='relu'))\n","  model.add(Dense(n_outputs, activation='sigmoid'))\n","  adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n","  #model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[keras_auc])\n","  model.compile(loss='logcosh', optimizer=adam, metrics=[keras_auc])\n","  return model\n","\n","def get_cnn_lstm_8layer(n_steps,n_length,n_signals): \n","  print('********************************************CNN(8 layer) + LSTM Arhitecture***************************************************')\n","  model = Sequential()\n","\n","  model.add(TimeDistributed(Conv1D(filters=16, kernel_size=3, activation='relu'),\n","                            input_shape=(n_steps,n_length,n_signals)))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(Conv1D(filters=16, kernel_size=3, activation='relu')))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n","  model.add(TimeDistributed(SpatialDropout1D(rate = 0.01)))\n","\n","  model.add(TimeDistributed(Conv1D(filters=32, kernel_size=3, activation='relu')))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(Conv1D(filters=32, kernel_size=3, activation='relu')))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n","  model.add(TimeDistributed(SpatialDropout1D(rate = 0.01)))\n","\n","  model.add(TimeDistributed(Conv1D(filters=32, kernel_size=3, activation='relu')))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(Conv1D(filters=32, kernel_size=3, activation='relu')))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n","  model.add(TimeDistributed(SpatialDropout1D(rate = 0.01)))\n","\n","  model.add(TimeDistributed(Conv1D(filters=256, kernel_size=3, activation='relu')))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(Conv1D(filters=256, kernel_size=3, activation='relu')))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n","  model.add(TimeDistributed(Flatten()))\n","\n","  model.add(LSTM(100))\n","  model.add(Dropout(0.5))\n","  model.add(Dense(100, activation='relu'))\n","  model.add(Dense(n_outputs, activation='sigmoid'))\n","\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[keras_auc])\n","  return model\n","\n","def get_2Class_cnn_lstm_8layer(n_steps,n_length,n_signals): \n","  print('********************************************CNN(8 layer) + LSTM Arhitecture***************************************************')\n","  model = Sequential()\n","\n","  model.add(TimeDistributed(Conv1D(filters=16, kernel_size=3, activation='relu'),\n","                            input_shape=(n_steps,n_length,n_signals)))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(Conv1D(filters=16, kernel_size=3, activation='relu')))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n","  model.add(TimeDistributed(SpatialDropout1D(rate = 0.01)))\n","\n","  model.add(TimeDistributed(Conv1D(filters=32, kernel_size=3, activation='relu')))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(Conv1D(filters=32, kernel_size=3, activation='relu')))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n","  model.add(TimeDistributed(SpatialDropout1D(rate = 0.01)))\n","\n","  model.add(TimeDistributed(Conv1D(filters=32, kernel_size=3, activation='relu')))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(Conv1D(filters=32, kernel_size=3, activation='relu')))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n","  model.add(TimeDistributed(SpatialDropout1D(rate = 0.01)))\n","\n","  model.add(TimeDistributed(Conv1D(filters=256, kernel_size=3, activation='relu')))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(Conv1D(filters=256, kernel_size=3, activation='relu')))\n","  model.add(BatchNormalization())\n","  model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n","  model.add(TimeDistributed(Flatten()))\n","\n","  model.add(LSTM(100))\n","  model.add(Dropout(0.5))\n","  model.add(Dense(100, activation='relu'))\n","  model.add(Dense(2, activation='sigmoid'))\n","\n","  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras_auc])\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MLfEhplay2pZ","colab_type":"code","colab":{}},"source":["dataSet, testDataSet, validDataSet = generateDataSets(signal_data1,signal_data2);#5 classes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LFoDL-UFvJjT","colab_type":"code","colab":{}},"source":["\n","table = BeautifulTable()\n","table.column_headers = [\"Arhitecture\",\"epohs\",\"acc\",\"confMat\"]\n","                        #\"MSE\", \"Correlation Coeficients\",\"Accuracy\",\"Sleep phase correlation\",\"F1-Score\",\"Accuracy-Sleep\", \"confussionMat\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYEbVAPi5X9n","colab_type":"code","colab":{}},"source":["n_outputs = 5 #Binary Classificatio\n","n_steps, n_length, n_signals,n_batch = 1,500, 2, 64\n","verbose, epochs, batch_size = True, 30, 128\n","clases = 5\n","weight = False\n","for j in range(10,11,1):\n","#for j in range(3,4,1):\n","  epochs = 10*j\n","  if n_length == 1000:\n","    interval = 23800\n","  elif n_length == 3000:\n","    interval = 2650\n","  else:\n","    interval = -1\n","  startIndex,endIndex = getFirstLastIndex(n_length,interval)\n","\n","\n","  model = get_cnn_lstm_8layer(n_steps,n_length,n_signals)\n","  weights_name = '/content/gdrive/My Drive/EEG/CNN8LSTM'+str(epochs)+str(n_length)+'.weights.best.hdf5'\n","  model.load_weights(weights_name)\n","  #train_model(model, dataSet,validDataSet,weights_name, epochs, batch_size, weight_loaded = weight, verbose = True,dim_shape = (n_batch,n_length,n_signals))\n","  filename = 'CNN-8 - LSTM Predicted Hypnogram'\n","  y_true, y_pred = predict_eeg_signal(model,filename,clases,dat_shape = (n_steps,n_length,n_signals))\n","  table.append_row([\"CNN(8layer)+LSTM\", epochs,\n"," #                   mean_squared_error(y_true[0:interval], y_pred[0:interval]),\n"," #                   np.corrcoef(y_true[0:interval], y_pred[0:interval]),\n"," #                   accuracy_score(y_true[0:interval], y_pred[0:interval]),\n"," #                   np.corrcoef(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval]),\n"," #                   f1_score(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval],average=None),\n","                    accuracy_score(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval]),\n","                    confusion_matrix(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval])\n","                   ])\n","  \n","  #BatchNormalization\n","  model = get_lstm_cnn2(n_steps, n_length, n_signals)\n","  weights_name = '/content/gdrive/My Drive/EEG/CNN2_LSTM_'+str(epochs)+str(n_length)+'.weights.best.hdf5'\n","  train_model(model, dataSet,validDataSet,weights_name, epochs, batch_size, weight_loaded = weight, verbose = True,dim_shape = (n_batch,n_length,n_signals))\n","  filename = 'sample_test_hypnogram_LSTM_CNN'+str(epochs)\n","  y_true, y_pred = predict_eeg_signal(model,filename,clases,dat_shape = (n_steps,n_length,n_signals))\n","  #model.load_weights(weights_name)\n","  table.append_row([\"CNN(2layer)+LSTM\", epochs, \n","  #                  mean_squared_error(y_true[0:interval], y_pred[0:interval]),\n","  #                  np.corrcoef(y_true[0:interval], y_pred[0:interval]),\n","  #                  accuracy_score(y_true[0:interval], y_pred[0:interval]),\n","  #                  np.corrcoef(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval]),\n","  #                  f1_score(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval],average=None),\n","                    accuracy_score(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval]),\n","                    confusion_matrix(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval])\n","                   ])\n"," \n","  model = get_cnn_8layer(n_length, n_signals)\n","  weights_name = '/content/gdrive/My Drive/EEG/CNN'+str(epochs)+str(n_length)+'.weights.best.hdf5'\n","  #rain_model(model, dataSet,validDataSet,weights_name, epochs, batch_size, weight_loaded = weight, expand=False, verbose = True,dim_shape = (n_batch,n_length,n_signals))\n","  model.load_weights(weights_name)\n","  filename = 'sample_test_hypnogram_CNN'+str(epochs)\n","  y_true, y_pred = predict_eeg_signal(model,filename,clases,expand_dim=False,dat_shape = (n_steps,n_length,n_signals))\n","  table.append_row([\"CNN\",  epochs,\n","  #                  mean_squared_error(y_true[0:interval], y_pred[0:interval]),\n","  #                  np.corrcoef(y_true[0:interval], y_pred[0:interval]),\n","  #                  accuracy_score(y_true[0:interval], y_pred[0:interval]),\n","  #                  np.corrcoef(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval]),\n","  #                  f1_score(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval],average=None),\n","                    accuracy_score(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval]),\n","                    confusion_matrix(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval])\n","                   ])\n","  \n","  model = get_lstm_network(n_length, n_signals)\n","  #model.summary()\n","  weights_name = '/content/gdrive/My Drive/EEG/LSTM'+str(epochs)+str(n_length)+'.weights.best.hdf5'\n","  model.load_weights(weights_name)\n","  #train_model(model, dataSet,validDataSet,weights_name, epochs, batch_size, weight_loaded = weight, expand=False, verbose = True,dim_shape = (n_batch,n_length,n_signals))\n","  filename = 'sample_test_hypnogram_LSTM'+str(epochs)\n","  y_true, y_pred = predict_eeg_signal(model,filename,clases,expand_dim=False,dat_shape = (n_steps,n_length,n_signals))\n","  table.append_row([\"LSTM\", epochs,\n","  #                  mean_squared_error(y_true[0:interval], y_pred[0:interval]),\n","  #                  np.corrcoef(y_true[0:interval], y_pred[0:interval]),\n","  #                  accuracy_score(y_true[0:interval], y_pred[0:interval]),\n","  #                  np.corrcoef(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval]),\n","  #                  f1_score(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval],average=None),\n","                    accuracy_score(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval]),\n","                    confusion_matrix(y_true[startIndex:endIndex-interval], y_pred[startIndex:endIndex-interval])\n","                   ])\n","  \n","filename = 'Original_hypnogram'\n","plot_original_eeg(filename,dat_shape = (n_steps,n_length,n_signals))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XFz47cWnILlR","colab_type":"code","colab":{}},"source":["print(table)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ICJkfU2qWVu","colab_type":"code","colab":{}},"source":["dataSet, testDataSet, validDataSet = generateSleepWakeDataSet(signal_data1,signal_data2);#2 classes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uacAUplAonPz","colab_type":"code","colab":{}},"source":["table = BeautifulTable()\n","table.column_headers = [\"Arhitecture\",\"epohs\",\"confMat\"]\n","                        #\"MSE\", \"Correlation Coeficients\",\"Accuracy\",\"Sleep phase correlation\",\"F1-Score\",\"Accuracy-Sleep\", \"confussionMat\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1hy7NshJ6b-P","colab_type":"code","outputId":"9a5f60e8-cc64-4c36-c256-cfc7f320257c","executionInfo":{"status":"ok","timestamp":1558716845027,"user_tz":-180,"elapsed":104601,"user":{"displayName":"Linda Kalašņikova","photoUrl":"","userId":"06739455726453495049"}},"colab":{"base_uri":"https://localhost:8080/","height":1955}},"source":["n_outputs = 2 #Binary Classificatio\n","n_steps, n_length, n_signals,n_batch = 1,500, 2, 64\n","verbose, epochs, batch_size = True, 30, 128\n","clases = 2\n","weight = False\n","#for j in range(10,11,1):\n","for j in range(5,6,1):\n","  epochs = 10*j\n","  if n_length == 1000:\n","    interval = 7500\n","  elif n_length == 3000:\n","    interval = 3650\n","  else:\n","    interval = -1\n","  startIndex,endIndex = getFirstLastIndex(n_length,interval)  \n","  \n","  \n","  \n","  model = get_lstm_cnn2(n_steps, n_length, n_signals)\n","  weights_name = '/content/gdrive/My Drive/EEG/CNN2LSTM_2Class_'+str(epochs)+str(n_length)+'.weights.best.hdf5'\n","  Fmodel.load_weights(weights_name)\n","  #train_model(model, dataSet,validDataSet,weights_name, epochs, batch_size, weight_loaded = weight, verbose = True,dim_shape = (n_batch,n_length,n_signals))\n","  filename = 'sample_test_hypnogram_LSTM_CNN'+str(epochs)\n","  y_true1, y_pred = predict_eeg_signal_sleep(model,filename,clases,dat_shape = (n_steps,n_length,n_signals))\n","  y_true = y = np.empty((len(y_pred)), dtype=int)\n","  for i in range(len(y_pred)-1):\n","    if y_true1[i][0] == 1:\n","      y_true[i] = 0\n","    if y_true1[i][1] == 1:\n","      y_true[i] = 1\n","  table.append_row([\"CNN2 - LSTM\", epochs,\n","                      confusion_matrix(y_true[3000:-1000], y_pred[3000:-1000])\n","                   ])\n","\n","  model = get_cnn_8layer(n_length, n_signals)\n","  weights_name = '/content/gdrive/My Drive/EEG/CNN_2class_'+str(epochs)+str(n_length)+'.weights.best.hdf5'\n","  train_model(model, dataSet,validDataSet,weights_name, epochs, batch_size, weight_loaded = weight, expand=False, verbose = True,dim_shape = (n_batch,n_length,n_signals))\n","  #model.load_weights(weights_name)\n","  filename = 'sample_test_hypnogram_CNN'+str(epochs)\n","  y_true1, y_pred = predict_eeg_signal_sleep(model,filename,clases,expand_dim=False,dat_shape = (n_steps,n_length,n_signals))\n","  y_true = y = np.empty((len(y_pred)), dtype=int)\n","  for i in range(len(y_pred)-1):\n","    if y_true1[i][0] == 1:\n","      y_true[i] = 0\n","    if y_true1[i][1] == 1:\n","      y_true[i] = 1\n","  table.append_row([\"CNN\", epochs,\n","                       confusion_matrix(y_true[3000:-1000], y_pred[3000:-1000])\n","                   ])\n","   \n","  \n","  \n","  model = get_2Class_cnn_lstm_8layer(n_steps,n_length,n_signals)\n","  #model.summary()\n","  weights_name = '/content/gdrive/My Drive/EEG/CNN8_LSTM_2Class'+str(epochs)+str(n_length)+'.weights.best.hdf5'\n","  #model.load_weights(weights_name)\n","  train_model(model, dataSet,validDataSet,weights_name, epochs, batch_size, weight_loaded = weight, expand=True, verbose = True,dim_shape = (n_batch,n_length,n_signals))\n","  filename = 'sample_test_hypnogram_LSTM_CNN'+str(epochs) \n","  y_true1, y_pred = predict_eeg_signal_sleep(model,filename,2,expand_dim=True,dat_shape = (n_steps,n_length,n_signals))\n","\n"," \n","  y_true = y = np.empty((len(y_pred)), dtype=int)\n","  for i in range(len(y_pred)-1):\n","    if y_true1[i][0] == 1:\n","      y_true[i] = 0\n","    if y_true1[i][1] == 1:\n","      y_true[i] = 1\n","  #print(y_true)\n","  #print(y_pred)\n","  table.append_row([\"CNN-8 - LSTM\", epochs,\n","                        confusion_matrix(y_true[3000:-1000], y_pred[3000:-1000])\n","                   ])\n","  \n","  \n","  \n","  model = get_lstm_network(n_length, n_signals)\n","  weights_name = '/content/gdrive/My Drive/EEG/LSTM_2Class_'+str(epochs)+str(n_length)+'.weights.best.hdf5'\n","  #model.load_weights(weights_name)\n","  train_model(model, dataSet,validDataSet,weights_name, epochs, batch_size, weight_loaded = weight, expand=False, verbose = True,dim_shape = (n_batch,n_length,n_signals))\n","  filename = 'sample_test_hypnogram_LSTM'+str(epochs)\n","  y_true1, y_pred = predict_eeg_signal_sleep(model,filename,clases,expand_dim=False,dat_shape = (n_steps,n_length,n_signals))\n","  \n","  y_true = y = np.empty((len(y_pred)), dtype=int)\n","  for i in range(len(y_pred)-1):\n","    if y_true1[i][0] == 1:\n","      y_true[i] = 0\n","    if y_true1[i][1] == 1:\n","      y_true[i] = 1\n","  table.append_row([\"LSTM\", epochs,\n","                      confusion_matrix(y_true[3000:-1000], y_pred[3000:-1000])\n","                   ])\n","  \n","  "],"execution_count":18,"outputs":[{"output_type":"stream","text":["['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","(15894, 1, 500, 2)\n","********************************************CNN Arhitecture***************************************************\n","Epoch 1/50\n","7/7 [==============================] - 6s 788ms/step - loss: 0.1174 - keras_auc: 0.5876 - val_loss: 0.1200 - val_keras_auc: 0.6729\n","Epoch 2/50\n","7/7 [==============================] - 1s 179ms/step - loss: 0.0677 - keras_auc: 0.7340 - val_loss: 0.1215 - val_keras_auc: 0.7695\n","Epoch 3/50\n","7/7 [==============================] - 1s 181ms/step - loss: 0.0412 - keras_auc: 0.8084 - val_loss: 0.0958 - val_keras_auc: 0.8318\n","Epoch 4/50\n","7/7 [==============================] - 1s 182ms/step - loss: 0.0299 - keras_auc: 0.8551 - val_loss: 0.0620 - val_keras_auc: 0.8720\n","Epoch 5/50\n","7/7 [==============================] - 1s 183ms/step - loss: 0.0225 - keras_auc: 0.8869 - val_loss: 0.0346 - val_keras_auc: 0.8997\n","Epoch 6/50\n","7/7 [==============================] - 1s 183ms/step - loss: 0.0153 - keras_auc: 0.9107 - val_loss: 0.0182 - val_keras_auc: 0.9201\n","Epoch 7/50\n","7/7 [==============================] - 1s 183ms/step - loss: 0.0134 - keras_auc: 0.9278 - val_loss: 0.0130 - val_keras_auc: 0.9344\n","Epoch 8/50\n","7/7 [==============================] - 1s 182ms/step - loss: 0.0107 - keras_auc: 0.9400 - val_loss: 0.0118 - val_keras_auc: 0.9450\n","Epoch 9/50\n","7/7 [==============================] - 1s 181ms/step - loss: 0.0091 - keras_auc: 0.9492 - val_loss: 0.0120 - val_keras_auc: 0.9528\n","Epoch 10/50\n","7/7 [==============================] - 1s 183ms/step - loss: 0.0081 - keras_auc: 0.9561 - val_loss: 0.0127 - val_keras_auc: 0.9589\n","Epoch 11/50\n","7/7 [==============================] - 1s 182ms/step - loss: 0.0088 - keras_auc: 0.9613 - val_loss: 0.0127 - val_keras_auc: 0.9635\n","Epoch 12/50\n","7/7 [==============================] - 1s 180ms/step - loss: 0.0068 - keras_auc: 0.9655 - val_loss: 0.0111 - val_keras_auc: 0.9673\n","Epoch 13/50\n","7/7 [==============================] - 1s 181ms/step - loss: 0.0062 - keras_auc: 0.9690 - val_loss: 0.0093 - val_keras_auc: 0.9706\n","Epoch 14/50\n","7/7 [==============================] - 1s 182ms/step - loss: 0.0057 - keras_auc: 0.9720 - val_loss: 0.0085 - val_keras_auc: 0.9732\n","Epoch 15/50\n","7/7 [==============================] - 1s 184ms/step - loss: 0.0049 - keras_auc: 0.9745 - val_loss: 0.0087 - val_keras_auc: 0.9755\n","Epoch 16/50\n","7/7 [==============================] - 1s 180ms/step - loss: 0.0056 - keras_auc: 0.9765 - val_loss: 0.0085 - val_keras_auc: 0.9774\n","Epoch 17/50\n","7/7 [==============================] - 1s 182ms/step - loss: 0.0057 - keras_auc: 0.9783 - val_loss: 0.0070 - val_keras_auc: 0.9790\n","Epoch 18/50\n","7/7 [==============================] - 1s 182ms/step - loss: 0.0039 - keras_auc: 0.9797 - val_loss: 0.0062 - val_keras_auc: 0.9804\n","Epoch 19/50\n","7/7 [==============================] - 1s 183ms/step - loss: 0.0052 - keras_auc: 0.9811 - val_loss: 0.0057 - val_keras_auc: 0.9816\n","Epoch 20/50\n","7/7 [==============================] - 1s 181ms/step - loss: 0.0039 - keras_auc: 0.9822 - val_loss: 0.0065 - val_keras_auc: 0.9827\n","Epoch 21/50\n","7/7 [==============================] - 1s 181ms/step - loss: 0.0033 - keras_auc: 0.9832 - val_loss: 0.0069 - val_keras_auc: 0.9836\n","Epoch 22/50\n","7/7 [==============================] - 1s 181ms/step - loss: 0.0036 - keras_auc: 0.9841 - val_loss: 0.0072 - val_keras_auc: 0.9845\n","Epoch 23/50\n","7/7 [==============================] - 1s 183ms/step - loss: 0.0042 - keras_auc: 0.9849 - val_loss: 0.0078 - val_keras_auc: 0.9852\n","Epoch 24/50\n","7/7 [==============================] - 1s 183ms/step - loss: 0.0033 - keras_auc: 0.9856 - val_loss: 0.0086 - val_keras_auc: 0.9859\n","Epoch 25/50\n","7/7 [==============================] - 1s 182ms/step - loss: 0.0033 - keras_auc: 0.9862 - val_loss: 0.0081 - val_keras_auc: 0.9865\n","Epoch 26/50\n","7/7 [==============================] - 1s 179ms/step - loss: 0.0033 - keras_auc: 0.9868 - val_loss: 0.0063 - val_keras_auc: 0.9870\n","Epoch 27/50\n","7/7 [==============================] - 1s 183ms/step - loss: 0.0035 - keras_auc: 0.9873 - val_loss: 0.0044 - val_keras_auc: 0.9875\n","Epoch 28/50\n","7/7 [==============================] - 1s 181ms/step - loss: 0.0035 - keras_auc: 0.9878 - val_loss: 0.0034 - val_keras_auc: 0.9880\n","Epoch 29/50\n","7/7 [==============================] - 1s 181ms/step - loss: 0.0031 - keras_auc: 0.9882 - val_loss: 0.0037 - val_keras_auc: 0.9884\n","Epoch 30/50\n","7/7 [==============================] - 1s 183ms/step - loss: 0.0040 - keras_auc: 0.9887 - val_loss: 0.0040 - val_keras_auc: 0.9888\n","Epoch 31/50\n","7/7 [==============================] - 1s 188ms/step - loss: 0.0037 - keras_auc: 0.9890 - val_loss: 0.0043 - val_keras_auc: 0.9891\n","Epoch 32/50\n","7/7 [==============================] - 1s 193ms/step - loss: 0.0025 - keras_auc: 0.9894 - val_loss: 0.0046 - val_keras_auc: 0.9895\n","Epoch 33/50\n","7/7 [==============================] - 1s 184ms/step - loss: 0.0029 - keras_auc: 0.9897 - val_loss: 0.0052 - val_keras_auc: 0.9898\n","Epoch 34/50\n","7/7 [==============================] - 1s 180ms/step - loss: 0.0032 - keras_auc: 0.9900 - val_loss: 0.0056 - val_keras_auc: 0.9901\n","Epoch 35/50\n","7/7 [==============================] - 1s 182ms/step - loss: 0.0030 - keras_auc: 0.9903 - val_loss: 0.0051 - val_keras_auc: 0.9904\n","Epoch 36/50\n","7/7 [==============================] - 1s 181ms/step - loss: 0.0026 - keras_auc: 0.9905 - val_loss: 0.0044 - val_keras_auc: 0.9906\n","Epoch 37/50\n","7/7 [==============================] - 1s 181ms/step - loss: 0.0025 - keras_auc: 0.9907 - val_loss: 0.0036 - val_keras_auc: 0.9908\n","Epoch 38/50\n","7/7 [==============================] - 1s 183ms/step - loss: 0.0026 - keras_auc: 0.9910 - val_loss: 0.0034 - val_keras_auc: 0.9911\n","Epoch 39/50\n","7/7 [==============================] - 1s 185ms/step - loss: 0.0025 - keras_auc: 0.9912 - val_loss: 0.0031 - val_keras_auc: 0.9913\n","Epoch 40/50\n","7/7 [==============================] - 1s 181ms/step - loss: 0.0029 - keras_auc: 0.9914 - val_loss: 0.0027 - val_keras_auc: 0.9915\n","Epoch 41/50\n","7/7 [==============================] - 1s 196ms/step - loss: 0.0030 - keras_auc: 0.9916 - val_loss: 0.0027 - val_keras_auc: 0.9917\n","Epoch 42/50\n","7/7 [==============================] - 1s 210ms/step - loss: 0.0027 - keras_auc: 0.9918 - val_loss: 0.0035 - val_keras_auc: 0.9919\n","Epoch 43/50\n","7/7 [==============================] - 1s 211ms/step - loss: 0.0025 - keras_auc: 0.9920 - val_loss: 0.0040 - val_keras_auc: 0.9920\n","Epoch 44/50\n","7/7 [==============================] - 1s 214ms/step - loss: 0.0025 - keras_auc: 0.9921 - val_loss: 0.0041 - val_keras_auc: 0.9922\n","Epoch 45/50\n","7/7 [==============================] - 1s 212ms/step - loss: 0.0024 - keras_auc: 0.9923 - val_loss: 0.0036 - val_keras_auc: 0.9923\n","Epoch 46/50\n","7/7 [==============================] - 1s 213ms/step - loss: 0.0031 - keras_auc: 0.9924 - val_loss: 0.0033 - val_keras_auc: 0.9925\n","Epoch 47/50\n","7/7 [==============================] - 1s 213ms/step - loss: 0.0021 - keras_auc: 0.9926 - val_loss: 0.0033 - val_keras_auc: 0.9926\n","Epoch 48/50\n","7/7 [==============================] - 1s 191ms/step - loss: 0.0022 - keras_auc: 0.9927 - val_loss: 0.0032 - val_keras_auc: 0.9928\n","Epoch 49/50\n","7/7 [==============================] - 1s 188ms/step - loss: 0.0020 - keras_auc: 0.9929 - val_loss: 0.0033 - val_keras_auc: 0.9929\n","Epoch 50/50\n","7/7 [==============================] - 1s 184ms/step - loss: 0.0017 - keras_auc: 0.9930 - val_loss: 0.0038 - val_keras_auc: 0.9930\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal', 'Event marker']\n","(15894, 500, 2)\n","Predicting...\n","keras_auc: 99.09%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SQM5-LxGZZY8","colab_type":"code","colab":{}},"source":["print(table)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bJB4YL5hoYo2","colab_type":"code","colab":{}},"source":["\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kYmepvDg4k2Y","colab_type":"code","colab":{}},"source":["\n","#data,sf = retrieveHypnogramData(hip_fil,eeg_fil)\n","#print(data)\n","#print(hypnogram_files[0])\n","#filename = 'Original_hypnogram'\n","#plot_original_eeg(filename,dat_shape = (n_steps,n_length,n_signals))\n","import numpy as np\n","ping = [x for x in os.listdir('/content/') if x.endswith(\".csv\")]\n","#print(ping)\n","for i in range(0,len(ping),1):\n","  myFile = np.genfromtxt(ping[i], delimiter=',')\n","  #show_sample_hypnogram(ping[i], start=950,stop=1800, title='SC4001EC-Hypnogram.csv')\n","  show_sample_hypnogram(ping[i], start=startIndex-100,stop=endIndex-interval-500,title ='Predictions for {}'.format(os.path.basename(ping[i])))\n","  #plot_hypnogram(myFile, title ='Predictions for {}'.format(os.path.basename(ping[i])))\n","  '/content/gdrive/My Drive/EEG/Test/SC4001EC-Hypnogram.edf'\n","  '/content/gdrive/My Drive/EEG/Test/SC4001E0-PSG.edf'\n","#filename = 'Original_hypnogram'\n","#plot_original_eeg(filename,dat_shape = (n_steps,1000,n_signals))\n","#print(endIndex)\n","#print(startIndex)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_FBUms_7lWyd","colab_type":"code","colab":{}},"source":["\"\"\"write/Read hypnogram data.\n","\n","Write hypnogram data\n","--------------------\n","-> write_hypno\n","    -> Export either using time code\n","        -> .txt, .csv, .xlsx\n","    -> Export using one sample per second\n","        -> .txt, .hyp\n","\n","Read hypnogram data\n","-------------------\n","-> read_hypno\n","    -> detect_hypno_version\n","        -> Sample :\n","            -> .txt, .csv, .xlsx\n","        -> Tieme :\n","            -> .txt, .hyp\n","\"\"\"\n","import os\n","import logging\n","import numpy as np\n","\n","\n","__all__ = ('oversample_hypno', 'write_hypno', 'read_hypno')\n","\n","logger = logging.getLogger('visbrain')\n","\n","\n","###############################################################################\n","###############################################################################\n","#                              HYPNO CONVERSION\n","###############################################################################\n","###############################################################################\n","def is_xlrd_installed(raise_error=False):\n","    \"\"\"Test if xlrd is installed.\"\"\"\n","    try:\n","        import xlrd  # noqa\n","        is_installed = True\n","    except:\n","        is_installed = False\n","    # Raise error (if needed) :\n","    if raise_error and not is_installed:\n","        raise IOError(\"xlrd not installed. In a terminal, run : pip install \"\n","                      \"xlrd\")\n","    return is_installed\n","\n","def is_pandas_installed(raise_error=False):\n","    \"\"\"Test if pandas is installed.\"\"\"\n","    try:\n","        import pandas  # noqa\n","        is_installed = True\n","    except:\n","        is_installed = False\n","    # Raise error (if needed) :\n","    if raise_error and not is_installed:\n","        raise IOError(\"pandas not installed. See https://pandas.pydata.org/#\"\n","                      \"best-way-to-install for installation instructions.\")\n","    return is_installed\n","\n","def vispy_array(data, dtype=np.float32):\n","    \"\"\"Check and convert array to be compatible with buffers.\n","\n","    Parameters\n","    ----------\n","    data : array_like\n","        Array of data.\n","    dtype : type | np.float32\n","        Futur type of the array.\n","\n","    Returns\n","    -------\n","    data : array_like\n","        Contiguous array of type dtype.\n","    \"\"\"\n","    if not data.flags['C_CONTIGUOUS']:\n","        data = np.ascontiguousarray(data, dtype=dtype)\n","    if data.dtype != dtype:\n","        data = data.astype(dtype, copy=False)\n","    return data\n","\n","def transient(data, xvec=None):\n","    \"\"\"Perform a transient detection on hypnogram.\n","\n","    Parameters\n","    ----------\n","    data : array_like\n","        The hypnogram data.\n","    xvec : array_like | None\n","        The time vector to use. If None, np.arange(len(data)) will be used\n","        instead.\n","\n","    Returns\n","    -------\n","    t : array_like\n","        Hypnogram's transients.\n","    st : array_like\n","        Either the transient index (as type int) if xvec is None, or the\n","        converted version if xvec is not None.\n","    stages : array_like\n","        The stages for each segment.\n","    \"\"\"\n","    # Transient detection :\n","    t = list(np.nonzero(np.abs(data[:-1] - data[1:]))[0])\n","    # Add first and last points :\n","    idx = np.vstack((np.array([-1] + t) + 1, np.array(t + [len(data) - 1]))).T\n","    # Get stages :\n","    stages = data[idx[:, 0]]\n","    # Convert (if needed) :\n","    if (xvec is not None) and (len(xvec) == len(data)):\n","        st = idx.copy().astype(float)\n","        st[:, 0] = xvec[idx[:, 0]]\n","        st[:, 1] = xvec[idx[:, 1]]\n","    else:\n","        st = idx\n","\n","    return np.array(t), st, stages.astype(int)\n","  \n","  \n","\n","def hypno_time_to_sample(df, npts):\n","    \"\"\"Convert the hypnogram from a defined timings to a number of samples.\n","\n","    Parameters\n","    ----------\n","    df : pandas.DataFrame\n","        The data frame that contains timing.\n","    npts : int, array_like\n","        Number of time points in the final hypnogram. Alternatively, if npts is\n","        an array it will be interprated as the time vector.\n","\n","    Returns\n","    -------\n","    hypno : array_like\n","        Hypnogram data of shape (npts,).\n","    time : array_like\n","        Time vector of shape (npts,).\n","    sf_hyp : float\n","        Sampling frequency of the hypnogram.\n","    \"\"\"\n","    # Drop lines that contains * :\n","    drop_rows = np.char.find(np.array(df['Stage']).astype(str), '*')\n","    df = df.iloc[drop_rows.astype(bool)]\n","    df.is_copy = False  # avoid pandas warning\n","    # Replace text by numerical values :\n","    to_replace = ['Wake', 'N1', 'N2', 'N3', 'REM', 'Art']\n","    values = [0, 1, 2, 3, 4, -1]\n","    df.replace(to_replace, values, inplace=True)\n","    # Get stages and time index :\n","    stages = np.array(df['Stage']).astype(str)\n","    time_idx = np.array(df['Time']).astype(float)\n","    # Compute time vector and sampling frequency :\n","    if isinstance(npts, np.ndarray):\n","        time = npts.copy()\n","    elif isinstance(npts, int):\n","        time = np.arange(npts) * time_idx[-1] / (npts - 1)\n","    sf_hyp = 1. / (time[1] - time[0])\n","    # Find closest time index :\n","    index = np.abs(time.reshape(-1, 1) - time_idx.reshape(1, -1))\n","    index = np.r_[0, index.argmin(0) + 1]\n","    # Fill the hypnogram :\n","    hypno = np.zeros((len(time),), dtype=int)\n","    for k in range(len(index) - 1):\n","        hypno[index[k]:index[k + 1]] = int(stages[k])\n","    return hypno, time, sf_hyp\n","\n","\n","def hypno_sample_to_time(hypno, time):\n","    \"\"\"Convert the hypnogram from a number of samples to a defined timings.\n","\n","    Parameters\n","    ----------\n","    hypno : array_like\n","        Hypnogram data.\n","    time : array_like\n","        The time vector.\n","\n","    Returns\n","    -------\n","    df : pandas.DataFrame\n","        The data frame that contains all of the transient timings.\n","    \"\"\"\n","    # Test if panda is installed :\n","    is_pandas_installed(True)\n","    import pandas as pd\n","    # Transient detection :\n","    _, tr, stages = transient(hypno, time)\n","    # Save the hypnogram :\n","    items = np.array(['Wake', 'N1', 'N2', 'N3', 'REM', 'Art'])\n","    return pd.DataFrame({'Stage': items[stages], 'Time': tr[:, 1]})\n","\n","\n","def oversample_hypno(hypno, n):\n","    \"\"\"Oversample hypnogram.\n","\n","    Parameters\n","    ----------\n","    hypno : array_like\n","        Hypnogram data of shape (N,) with N < n.\n","    n : int\n","        The destination length.\n","\n","    Returns\n","    -------\n","    hypno : array_like\n","        The hypnogram of shape (n,)\n","    \"\"\"\n","    # Get the repetition number :\n","    rep_nb = int(np.round(n / len(hypno)))\n","\n","    # Repeat hypnogram :\n","    hypno = np.repeat(hypno, rep_nb)\n","    npts = len(hypno)\n","\n","    # Check size\n","    if npts < n:\n","        hypno = np.append(hypno, hypno[-1] * np.ones((n - npts)))\n","    elif npts > n:\n","        hypno = hypno[0:n]\n","\n","    return hypno.astype(int)\n","\n","\n","###############################################################################\n","###############################################################################\n","#                               WRITE HYPNO\n","###############################################################################\n","###############################################################################\n","\n","def write_hypno(filename, hypno, version='time', sf=100., npts=1, window=1.,\n","                time=None, info=None):\n","    \"\"\"Save hypnogram data.\n","\n","    Parameters\n","    ----------\n","    filename : str\n","        Filename (with full path) of the file to save\n","    hypno : array_like\n","        Hypnogram array, same length as data\n","    sf : float | 100.\n","        Original sampling rate of the raw data\n","    npts : int | 1\n","        Original number of points in the raw data\n","    window : float | 1\n","        Time window (second) of each point in the hypno\n","        Default is one value per second\n","        (e.g. window = 30 = 1 value per 30 second)\n","    time : array_like | None\n","        The time vector.\n","    info : dict | None\n","        Additional informations to add to the file (prepend with *).\n","    \"\"\"\n","    # Checking :\n","    assert isinstance(filename, str)\n","    assert isinstance(hypno, np.ndarray)\n","    assert version in ['time', 'sample']\n","    # Extract file extension :\n","    _, ext = os.path.splitext(filename)\n","    # Switch between time and sample version :\n","    if version is 'sample':  # v1 = sample\n","        # Take a down-sample version of the hypno :\n","        step = int(len(hypno) / np.round(npts / sf))\n","        hypno = hypno[::step].astype(int)\n","        # Export :\n","        if ext == '.txt':\n","            _write_hypno_txt_sample(filename, hypno, window=window)\n","        elif ext == '.hyp':\n","            _write_hypno_hyp_sample(filename, hypno, sf=sf, npts=npts)\n","    elif version is 'time':  # v2 = time\n","        # Get the DataFrame :\n","        df = hypno_sample_to_time(hypno, time)\n","        if isinstance(info, dict):\n","            is_pandas_installed(True)\n","            import pandas as pd\n","            info = {'*' + k: i for k, i in info.items()}\n","            df_info = pd.DataFrame({'Stage': list(info.keys()),\n","                                    'Time': list(info.values())})\n","            df = df_info.append(df)\n","        if ext in ['.txt', '.csv']:\n","            df.to_csv(filename, header=None, index=None, sep='\\t', mode='a')\n","        elif ext == '.xlsx':\n","            is_pandas_installed(True)\n","            is_xlrd_installed(True)\n","            import pandas as pd\n","            writer = pd.ExcelWriter(filename)\n","            df.to_excel(writer, sheet_name='Data', index=False, header=False)\n","            writer.save()\n","    logger.info(\"Hypnogram saved (%s)\" % filename)\n","\n","\n","def _write_hypno_txt_sample(filename, hypno, window=1.):\n","    \"\"\"Save hypnogram in txt file format (txt).\n","\n","    Header is in file filename_description.txt\n","\n","    Parameters\n","    ----------\n","    filename : str\n","        Filename (with full path) of the file to save\n","    hypno : array_like\n","        Hypnogram array, same length as data\n","    window : float | 1\n","        Time window (second) of each point in the hypno\n","        Default is one value per second\n","        (e.g. window = 30 = 1 value per 30 second)\n","    \"\"\"\n","    base = os.path.basename(filename)\n","    dirname = os.path.dirname(filename)\n","    descript = os.path.join(dirname, os.path.splitext(\n","        base)[0] + '_description.txt')\n","\n","    # Save hypno\n","    np.savetxt(filename, hypno, fmt='%s')\n","\n","    # Save header file\n","    hdr = np.array([['time ' + str(window)], ['W 0'], ['N1 1'], ['N2 2'],\n","                    ['N3 3'], ['REM 4'], ['Art -1']]).flatten()\n","    np.savetxt(descript, hdr, fmt='%s')\n","\n","\n","def _write_hypno_hyp_sample(filename, hypno, sf=100., npts=1):\n","    \"\"\"Save hypnogram in Elan file format (hyp).\n","\n","    Parameters\n","    ----------\n","    filename : str\n","        Filename (with full path) of the file to save\n","    hypno : array_like\n","        Hypnogram array, same length as data\n","    sf : float | 100.\n","        Original sampling rate of the raw data\n","    npts : int | 1\n","        Original number of points in the raw data\n","    \"\"\"\n","    hypno[hypno == 4] = 5\n","\n","    hdr = np.array([['time_base 1.000000'],\n","                    ['sampling_period ' + str(np.round(1 / sf, 8))],\n","                    ['epoch_nb ' + str(int(npts / sf))],\n","                    ['epoch_list']]).flatten()\n","\n","    # Save\n","    export = np.append(hdr, hypno.astype(str))\n","    np.savetxt(filename, export, fmt='%s')\n","\n","\n","###############################################################################\n","###############################################################################\n","#                                 READ HYPNO\n","###############################################################################\n","###############################################################################\n","\n","\n","def read_hypno(filename, time=None, datafile=None):\n","    \"\"\"Load hypnogram file.\n","\n","    Sleep stages in the hypnogram should be scored as follow\n","    see Iber et al. 2007\n","\n","    Wake:   0\n","    N1:     1\n","    N2:     2\n","    N3:     3\n","    REM:    4\n","    Art:    -1  (optional)\n","\n","    Parameters\n","    ----------\n","    filename : string\n","        Filename (with full path) to hypnogram file.\n","    time : array_like | None\n","        The time vector (used to interpolate Excel files).\n","    datafile : string | None\n","        Filename (with full path) to the data file.\n","\n","    Returns\n","    -------\n","    hypno : array_like\n","        The hypnogram vector in its original length.\n","    sf_hyp: float\n","        The hypnogram original sampling frequency (Hz)\n","    \"\"\"\n","    # Test if file exist :\n","    assert os.path.isfile(filename)\n","\n","    # Extract file extension :\n","    file, ext = os.path.splitext(filename)\n","\n","    # Load the hypnogram :\n","    if ext == '.hyp':  # v1 = ELAN\n","        hypno, sf_hyp = _read_hypno_hyp_sample(filename)\n","    elif ext == '.edf':  # v1 = EDF+\n","        hypno, sf_hyp = _read_hypno_edf_sample(filename, datafile)\n","    elif ext in ['.txt', '.csv']:  # [v1, v2] = TXT / CSV\n","        header = os.path.splitext(filename)[0] + '_description.txt'\n","        if os.path.isfile(header):  # if there's a header -> v1\n","            hypno, sf_hyp = _read_hypno_txt_sample(filename)\n","        else:  # v2\n","            import pandas as pd\n","            df = pd.read_csv(filename, delim_whitespace=True, header=None,\n","                             names=['Stage', 'Time'])\n","            hypno, _, sf_hyp = hypno_time_to_sample(df, len(time))\n","    elif ext == '.xlsx':  # v2 = Excel\n","        import pandas as pd\n","        df = pd.read_excel(filename, header=None, names=['Stage', 'Time'])\n","        hypno, _, sf_hyp = hypno_time_to_sample(df, len(time))\n","\n","    logger.info(\"Hypnogram successfully loaded (%s)\" % filename)\n","\n","    return vispy_array(hypno), sf_hyp\n","\n","\n","def _read_hypno_hyp_sample(path):\n","    \"\"\"Read Elan hypnogram (hyp).\n","\n","    Parameters\n","    ----------\n","    path : str\n","        Filename(with full path) to Elan .hyp file\n","\n","    Returns\n","    -------\n","    hypno : array_like\n","        The hypnogram vector in its original length.\n","    sf_hyp : float\n","        The hypnogram original sampling frequency (Hz)\n","    \"\"\"\n","    hyp = np.genfromtxt(path, delimiter='\\n', usecols=[0],\n","                        dtype=None, skip_header=0, encoding='utf-8')\n","\n","    # Get sampling frequency of hypnogram\n","    sf_hyp = 1 / float(hyp[0].split()[1])\n","\n","    # Extract hypnogram values\n","    hypno = np.array(hyp[4:], dtype=np.int)\n","\n","    # Replace values according to Iber et al 2007\n","    hypno[hypno == -2] = -1\n","    hypno[hypno == 4] = 3\n","    hypno[hypno == 5] = 4\n","\n","    return hypno, sf_hyp\n","\n","\n","def _read_hypno_txt_sample(path):\n","    \"\"\"Read text files (.txt / .csv) hypnogram.\n","\n","    Parameters\n","    ----------\n","    path : str\n","        Filename(with full path) to hypnogram (.txt)\n","\n","    Returns\n","    -------\n","    hypno : array_like\n","        The hypnogram vector in its original length.\n","    sf_hyp : float\n","        The hypnogram original sampling frequency (Hz)\n","    \"\"\"\n","    assert os.path.isfile(path)\n","\n","    file, ext = os.path.splitext(path)\n","\n","    header = file + '_description.txt'\n","    assert os.path.isfile(header)\n","\n","    # Load header file\n","    labels = np.genfromtxt(header, dtype=str, delimiter=\" \", usecols=0,\n","                           encoding='utf-8')\n","    values = np.genfromtxt(header, dtype=float, delimiter=\" \", usecols=1,\n","                           encoding='utf-8')\n","    desc = {label: row for label, row in zip(labels, values)}\n","\n","    # Get sampling frequency of hypnogram\n","    sf_hyp = 1. / float(desc['time'])\n","\n","    # Load hypnogram file\n","    hyp = np.genfromtxt(path, delimiter='\\n', usecols=[0],\n","                        dtype=None, skip_header=0, encoding='utf-8')\n","\n","    if not np.issubdtype(hyp.dtype, np.integer):\n","        hypno = np.array([s for s in hyp if s.lstrip('-').isdigit()],\n","                         dtype=int)\n","    else:\n","        hypno = hyp.astype(int)\n","\n","    hypno = swap_hyp_values(hypno, desc)\n","\n","    return hypno, sf_hyp\n","\n","\n","def _read_hypno_edf_sample(hypno_file_path, data_file_path):\n","    \"\"\"Read hypnogram files which are formatted according to EDF+.\n","\n","    See file specifications (see https://www.edfplus.info/specs/index.html).\n","    The function was specifically developed to read hypnograms which are part\n","    of the Physionet Sleep Database (https://physionet.org/pn4/sleep-edfx/).\n","    The Physionet Sleep Database contains 61 polysomnograms (PSGs) with\n","    accompanying hypnograms. The Physionet polysomnogram files are using edf\n","    format, while the hypnograms use EDF+. When using EDF+ for hypnograms, the\n","    data records contain Timestamped Annotation Lists (TALs). Each TAL consists\n","    of an onset, a duration, and a sleep stage. The following assumptions have\n","    been made:\n","    - the scoring period for the hypnogram is equal to the number of seconds\n","      per data record as given by header information of the accompanying\n","      polysomnogram file\n","    - all EDF+ hypnogram files use the same scoring for sleep stages which are\n","      in the function converted to the values used by Visbrain:\n","            EDF+ score                    Visbrain\n","          Sleep stage ?                      -1\n","          Movement time                      -1\n","          Sleep stage W                       0\n","          Sleep stage 1                       1\n","          Sleep stage 2                       2\n","          Sleep stage 3                       3\n","          Sleep stage 4                       3\n","          Sleep stage R                       4\n","\n","    The Physionet hypnogram files (EDF+) sometimes cover a slightly longer\n","    total period than the polysomnograph files, where the score for the last\n","    part is set to \"Sleep stage ?\". This function will only read the hypnogram\n","    files so that only the time period of the polysomnograph is covered.\n","\n","    The function will check whether the hypnogram file is the appropriate\n","    accompanying file to the polysomnogranph file by comparing the \"subjcet_id\"\n","    as well as the \"recording_id\" of the two files.\n","\n","    Parameters\n","    ----------\n","    data_file_path : str\n","        Filename(with full path) to data(.edf)\n","    hypno_file_path : str\n","        Filename(with full path) to corresponding hypnogram(.edf)\n","\n","    Returns\n","    -------\n","    hypno : array_like\n","        The hypnogram vector in its original length.\n","    sf_hyp : float\n","        The hypnogram original sampling frequency (Hz)\n","    \"\"\"\n","    if not isinstance(data_file_path, str):\n","        raise IOError(\"Reading EDF+ need the path to the data file.\")\n","    data_file_path, _ = os.path.splitext(data_file_path)\n","\n","    with open(data_file_path + '.edf', 'rb') as f:  # open edf data file\n","        hdr1 = {}\n","        assert f.tell() == 0\n","        assert f.read(8) == b'0       '\n","\n","        # Recording info (patient info and date and time)\n","        hdr1['subject_id'] = f.read(80).decode('utf-8').strip()\n","        hdr1['recording_id'] = f.read(80).decode('utf-8').strip()\n","\n","        f.seek(68, 1)\n","        hdr1['n_records'] = int(f.read(8))\n","        hdr1['record_length'] = float(f.read(8))  # in seconds\n","        end_file = str(int(hdr1['n_records'] * hdr1['record_length']))\n","\n","    with open(hypno_file_path, 'rb') as f:  # open edf hypnogram file\n","        hdr2 = {}\n","        assert f.tell() == 0\n","        assert f.read(8) == b'0       '\n","\n","        # Recording info (patient info and date and time)\n","        hdr2['subject_id'] = f.read(80).decode('utf-8').strip()\n","        hdr2['recording_id'] = f.read(80).decode('utf-8').strip()\n","\n","        # Compare the patient info and recording date of the two files\n","        if not (hdr1['subject_id'] == hdr2['subject_id'] and hdr1[\n","                'recording_id'] == hdr2['recording_id']):\n","            raise IOError(\"Hypnogram file does not match polysomnograph file\")\n","\n","        # skip records not required\n","        f.seek(16, 1)\n","        # read bytes in header of hypnogram file\n","        hdr2['header_n_bytes'] = int(f.read(8))\n","\n","        # go to the end of the header info```\n","        f.seek(hdr2['header_n_bytes'])\n","\n","        data_hypno = f.read().decode('utf-8')  # read the data\n","\n","    # number of secs per data record used for score period\n","    time = hdr1['record_length']\n","    data_hypno_spl = data_hypno.split('\\x00')\n","    ln = len(data_hypno_spl)\n","    tr = {'Sleep stage ?': -1, 'Movement time': -1, 'Sleep stage W': 0,\n","          'Sleep stage 1': 1, 'Sleep stage 2': 2, 'Sleep stage 3': 3,\n","          'Sleep stage 4': 3, 'Sleep stage R': 4}\n","    hypno_s = []\n","    for i in range(ln):\n","        in_start = data_hypno_spl[i].find('\\x15')\n","        if in_start == -1:\n","            continue\n","        else:\n","            in_stop = data_hypno_spl[i].find('\\x14')\n","            onset = data_hypno_spl[i][1:in_start]\n","            duration = data_hypno_spl[i][in_start + 1:in_stop]\n","\n","            if int(onset) + int(duration) >= int(end_file):\n","                duration = str(int(end_file) - int(onset))\n","\n","            sleepstage = data_hypno_spl[i][in_stop + 1:-1]\n","\n","            nr = int(int(duration) / 30)\n","            entry = [tr[sleepstage]] * nr\n","            hypno_s.extend(entry)\n","\n","    hypno_s = np.array(hypno_s).astype(int)\n","    sf_hyp = 1. / time\n","    return hypno_s, sf_hyp\n","\n","\n","def swap_hyp_values(hypno, desc):\n","    \"\"\"Swap values in hypnogram vector.\n","\n","    Sleep stages in the hypnogram should be scored as follow\n","    see Iber et al. 2007\n","\n","    e.g from the DREAM bank EDF database\n","    Stage   Orig. val    New val\n","    W       5           0\n","    N1      3           1\n","    N2      2           2\n","    N3      1           3\n","    REM     0           4\n","\n","    Parameters\n","    ----------\n","    hypno : array_like\n","        The hypnogram vector\n","    description : str\n","        Path to a .txt file containing labels and values of each sleep\n","        stage separated by a space\n","\n","    Returns\n","    -------\n","    hypno_s : array_like\n","        Hypnogram with swapped values\n","    \"\"\"\n","    # Swap values\n","    hypno_s = -1 * np.ones(shape=(hypno.shape), dtype=int)\n","\n","    if 'Art' in desc:\n","        hypno_s[hypno == desc['Art']] = -1\n","    if 'Nde' in desc:\n","        hypno_s[hypno == desc['Nde']] = -1\n","    if 'Mt' in desc:\n","        hypno_s[hypno == desc['Mt']] = -1\n","    if 'W' in desc:\n","        hypno_s[hypno == desc['W']] = 0\n","    if 'N1' in desc:\n","        hypno_s[hypno == desc['N1']] = 1\n","    if 'N2' in desc:\n","        hypno_s[hypno == desc['N2']] = 2\n","    if 'N3' in desc:\n","        hypno_s[hypno == desc['N3']] = 3\n","    if 'N4' in desc:\n","        hypno_s[hypno == desc['N4']] = 3\n","    if 'REM' in desc:\n","        hypno_s[hypno == desc['REM']] = 4\n","\n","    return hypno_s\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVUayY3LmolZ","colab_type":"code","colab":{}},"source":["\"\"\"Export graphical components as figures.\n","\n","- write_fig_hyp : Export the hypnogram as a figure\n","- write_fig_canvas : Export a canvas as a figure\n","- write_fig_pyqt : Export a GUI window as a figure\n","\"\"\"\n","import os\n","import logging\n","import numpy as np\n","\n","logger = logging.getLogger('visbrain')\n","\n","__all__ = ('write_fig_hyp', 'write_fig_spindles', 'write_fig_canvas',\n","           'write_fig_pyqt')\n","\n","\n","def write_fig_hyp(data, sf, file=None, start_s=0, grid=False, ascolor=False,\n","                  dpi=300, colors={-1: '#8bbf56', 0: '#56bf8b', 1: '#aabcce',\n","                                   2: '#405c79', 3: '#0b1c2c', 4: '#bf5656'}):\n","    \"\"\"Export hypnogram to a high-res png figure.\n","\n","    Parameters\n","    ----------\n","    data : array_like\n","        Hypnogram vector\n","    sf : float\n","        The sampling frequency of displayed elements (could be the\n","        down-sampling frequency)\n","    file : string | None\n","        Output filename (with full path). If None, the plot is displayed.\n","    start_s : float | 0.\n","        Record starting time given in seconds.\n","    grid : bool | False\n","        Plot X and Y grid.\n","    ascolor : bool | False\n","        Plot in color\n","    dpi : int | 600\n","        Dots per inches\n","    color : dict | {}\n","        Color for each sleep stage. Default is : {-1: '#8bbf56', 0: '#56bf8b',\n","        1: '#aabcce', 2: '#405c79', 3: '#0b1c2c', 4: '#bf5656'}\n","    \"\"\"\n","    import matplotlib.pyplot as plt\n","    import datetime\n","\n","    # Internal copy :\n","    hypno = data.copy()\n","\n","    # Downsample to get one value per second\n","    sf = int(sf)\n","    hypno = hypno[::sf]\n","\n","    # Put REM between Wake and N1 sleep\n","    hypno[hypno >= 1] += 1\n","    hypno[hypno == 5] = 1\n","    idx_rem = np.where(hypno == 1)[0]\n","    val_rem = np.zeros(hypno.size)\n","    val_rem[:] = np.nan\n","    val_rem[idx_rem] = 1\n","\n","    # Find if artefacts are present in hypno\n","    art = True if -1 in hypno else False\n","\n","    # Start plotting\n","    fig, ax = plt.subplots(figsize=(8, 3), edgecolor='k')\n","    lhyp = len(hypno) / 60\n","    lw = 1.5\n","    if lhyp < 60:\n","        xticks = np.arange(0, len(hypno), 10 * 60)\n","        lw = 2\n","    elif lhyp < 180 and lhyp > 60:\n","        xticks = np.arange(0, len(hypno), 30 * 60)\n","    else:\n","        xticks = np.arange(0, len(hypno), 60 * 60)\n","\n","    xticks = np.append(xticks, len(hypno))\n","    xlabels = (xticks + start_s).astype(int)\n","    xlabels_str = [str(datetime.timedelta(seconds=int(j)))[:-3]\n","                   for i, j in enumerate(xlabels)]\n","    xlabels_str = [s.replace('1 day, ', '') for s in xlabels_str]\n","    plt.xlim(0, len(hypno))\n","    plt.xticks(xticks, xlabels_str)\n","    if not ascolor:\n","        plt.plot(hypno, 'k', ls='steps', linewidth=lw)\n","    else:\n","        for k, i in colors.items():\n","            # Quick and dirty switch :\n","            if k == 1:\n","                q = 2\n","            elif k == 4:\n","                q = 1\n","            elif k in [2, 3]:\n","                q = k + 1\n","            else:\n","                q = k\n","            mask = np.ones((len(hypno),), dtype=bool)\n","            idxm = np.where(hypno == q)[0] + 1\n","            idxm[idxm >= len(hypno)] = len(hypno) - 1\n","            mask[idxm] = False\n","            plt.plot(np.ma.masked_array(hypno, mask=mask), i, ls='steps',\n","                     linewidth=lw)\n","\n","    # Plot REM epochs\n","    remcol = 'k' if not ascolor else colors[4]\n","    for i in np.arange(0.6, 1, 0.01):\n","        plt.plot(np.arange(len(hypno)), i * val_rem, remcol, linewidth=lw)\n","\n","    # Y-Ticks and Labels\n","    if art:\n","        ylabels = ['Art', 'Wake', 'REM', 'N1', 'N2', 'N3']\n","        plt.yticks([-1, 0, 1, 2, 3, 4], ylabels)\n","        plt.ylim(-1.5, 4.5)\n","    else:\n","        ylabels = ['', 'Wake', 'REM', 'N1', 'N2', 'N3']\n","        plt.yticks([-0.5, 0, 1, 2, 3, 4], ylabels)\n","        plt.ylim(-.5, 4.5)\n","\n","    # X-Ticks and Labels\n","    plt.xlabel(\"Time\")\n","    plt.ylabel(\"Sleep Stage\")\n","\n","    # Grid\n","    if grid:\n","        plt.grid(True, 'major', ls=':', lw=.2, c='k', alpha=.3)\n","\n","    plt.tick_params(axis='both', which='both', bottom=True, top=False,\n","                    labelbottom=True, left=True, right=False, labelleft=True,\n","                    labelcolor='k', direction='out')\n","\n","    # Invert Y axis and despine\n","    ax.invert_yaxis()\n","    ax.spines['right'].set_visible(False)\n","    ax.spines['top'].set_visible(False)\n","    ax.spines['left'].set_visible(True)\n","    ax.spines['bottom'].set_visible(True)\n","\n","    ax.spines['left'].set_position(('outward', 10))\n","    ax.spines['bottom'].set_position(('outward', 10))\n","    ax.spines['bottom'].set_smart_bounds(True)\n","\n","    # Save as 600 dpi .png\n","    if isinstance(file, str):\n","        plt.savefig(file, format='png', dpi=dpi, bbox_inches='tight')\n","        logger.info('Image successfully saved (%s)' % file)\n","        plt.close()\n","    else:\n","        plt.show()\n","\n","\n","def write_fig_spindles(data, sf, hypno=None, file=None, start_s=0.,\n","                       window_s=10., thr=3., nrem_only=False, dpi=300):\n","    \"\"\"Show steps of the spindles detection for a specific time window.\n","\n","    Parameters\n","    ----------\n","    data : array_like\n","        Data vector\n","    sf : float\n","        The sampling frequency of displayed elements (could be the\n","        down-sampling frequency)\n","    hypno : array_like | None\n","        Hypnogram vector\n","    file : string | None\n","        Output filename (with full path). If None, the plot is displayed.\n","    start_s : float | 0.\n","        Starting point in sec of the window to plot\n","    window_s : float | 10.\n","        Window duration in seconds\n","    thresh : float | 3\n","        Hard threshold for the spindles detection\n","    dpi : int | 300\n","        Dots per inches\n","    \"\"\"\n","    import matplotlib.pyplot as plt\n","    from ..utils.sleep import spindlesdetect\n","    from ..utils.filtering import filt\n","\n","    # Define an empty hypno hypnogram if None :\n","    hypno = np.zeros_like(data) if hypno is None else hypno\n","\n","    # Run spindles detection on the selected channel\n","    (idx_spindles, _, _, dur, pwr, idx_start, idx_stop, hard_thr, soft_thr,\n","     idx_sigma, fmin, fmax, sigma_nfpow, amplitude,\n","     sigma_thr) = spindlesdetect(data, sf, thr, hypno, nrem_only,\n","                                 return_full=True)\n","\n","    # Define plotting range\n","    start_sf = int(start_s * sf)\n","    x = range(start_sf, start_sf + int(window_s * sf))\n","\n","    # Bandpass filter of the window\n","    elec_filt = filt(sf, [12., 14.], data[x], order=4)\n","\n","    # Find beginning and end of spindle within the window\n","    idx_start_win = idx_start[(idx_start >= min(x)) & (idx_start <= max(x))]\n","    idx_stop_win = idx_stop[(idx_stop >= min(x)) & (idx_stop <= max(x))]\n","    sp_in_win = np.in1d(idx_start, idx_start_win)\n","    sp_power = pwr[sp_in_win]\n","    sp_duration = dur[sp_in_win]\n","\n","    # Find indices of spindles within the window\n","    idx_spindles_win = idx_spindles[\n","        (idx_spindles >= min(x)) & (idx_spindles <= max(x))]\n","\n","    # Find indices of sigma power > supra-threshold within window\n","    idx_sigma_win = idx_sigma[(idx_sigma > min(x)) & (idx_sigma < max(x))]\n","    # Find indices of wavelet amplitude > supra-threshold within window\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        idx_hard = np.where(amplitude > hard_thr)[0]\n","\n","    idx_hard_win = idx_hard[(idx_hard > min(x)) & (idx_hard < max(x))]\n","\n","    # Initialize Y vector\n","    y_sigma, y_spindles, y_wlt, y_hard = np.empty(len(x)), np.empty(len(x)), \\\n","        np.empty(len(x)), np.empty(len(x))\n","    y_sigma[:], y_spindles[:], y_wlt[:], y_hard[:] = np.nan, np.nan, np.nan, \\\n","        np.nan\n","\n","    # Fill Y vector\n","    y_sigma[idx_sigma_win - start_sf] = sigma_nfpow[idx_sigma_win]\n","    y_spindles[idx_spindles_win - start_sf] = data[idx_spindles_win]\n","    y_wlt[idx_spindles_win - start_sf] = amplitude[idx_spindles_win]\n","    y_hard[idx_hard_win - start_sf] = amplitude[idx_hard_win]\n","\n","    # Start plot\n","    f, axarr = plt.subplots(4, figsize=(10, 6), sharex=True)\n","    f.subplots_adjust(hspace=0.6)\n","\n","    # Plot original signal\n","    axarr[0].plot(x, data[x], 'darkslategrey', lw=1.5)\n","    axarr[0].plot(x, y_spindles, 'brown', lw=1.5)\n","    axarr[0].set_title('Original signal (' + str(window_s) + ' sec)')\n","    axarr[0].set_xlim([min(x), max(x)])\n","\n","    if sp_power.size >= 1:\n","        text = 'power = ' + str(np.round(sp_power, 2)) + \\\n","            ' - duration = ' + str(sp_duration) + ' ms'\n","        axarr[0].annotate(text, xy=(min(x), min(data[x])), fontsize=9,\n","                          xycoords='data')\n","\n","    # Plot filtered signal\n","    axarr[1].plot(x, elec_filt, 'darkslategrey', linewidth=1.5)\n","    axarr[1].set_title('Filtered')\n","\n","    # Plot wavelet envelope\n","    axarr[2].plot(x, amplitude[x], 'darkslategrey', linewidth=2)\n","    axarr[2].plot(x, y_wlt, 'coral', lw=3)\n","    # axarr[2].plot(x, y_hard, 'indianred', lw=3)\n","    axarr[2].scatter(idx_start_win, amplitude[idx_start_win], 60, 'coral')\n","    axarr[2].scatter(idx_stop_win, amplitude[idx_stop_win], 60, 'coral')\n","    axarr[2].set_title('Wavelet')\n","    axarr[2].axhline(y=hard_thr, color='grey', linestyle=':', lw=1.5)\n","    axarr[2].axhline(y=soft_thr, color='grey', linestyle=':', lw=1.5)\n","\n","    # Plot sigma normalized power\n","    axarr[3].plot(x, sigma_nfpow[x], 'darkslategrey', linewidth=2)\n","    axarr[3].set_title('Sigma power')\n","    axarr[3].plot(x, y_sigma, lw=3, color='lightcoral')\n","    axarr[3].axhline(y=sigma_thr, color='grey', linestyle=':', lw=1.5)\n","\n","    # Despine\n","    for ax in range(4):\n","        axarr[ax].axis('off')\n","\n","    # Save as .png\n","    if isinstance(file, str):\n","        plt.savefig(file, format='png', dpi=dpi, bbox_inches='tight')\n","        logger.info('Image successfully saved (%s)' % file)\n","        plt.close()\n","    else:\n","        plt.show()\n","\n","\n","def write_fig_canvas(filename, canvas, widget=None, autocrop=False,\n","                     region=None, print_size=None, unit='centimeter', dpi=300.,\n","                     factor=1., bgcolor=None, transparent=False):\n","    \"\"\"Export a canvas as a figure.\n","\n","    Parameters\n","    ----------\n","    filename : string\n","        Name of the figure to export.\n","    canvas : VisPy canvas\n","        The vispy canvas to export.\n","    widget : PyQt widget | None\n","        The widget parent of the canvas.\n","    autocrop : bool | False\n","        Auto-cropping argument to remove useless space.\n","    region : tuple/list | None\n","        The region to export (x_start, y_start, width, height).\n","    print_size : tuple | None\n","        The desired print size. This argument should be used in association\n","        with the dpi and unit inputs. print_size describe should be a tuple\n","        of two floats describing (width, height) of the exported image for\n","        a specific dpi level. The final image might not have the exact\n","        desired size but will try instead to find a compromize\n","        regarding to the proportion of width/height of the original image.\n","    unit : {'centimeter', 'millimeter', 'pixel', 'inch'}\n","        Unit of the printed size.\n","    dpi : float | 300.\n","        Dots per inch for printing the image.\n","    factor : float | None\n","        If you don't want to use the print_size input, factor simply\n","        multiply the resolution of your screen.\n","    bgcolor : array_like/string | None\n","        Background color of the canvas.\n","    transparent : bool | False\n","        Use transparent background.\n","    \"\"\"\n","    from ..utils import piccrop\n","    from vispy.io import imsave\n","\n","    # Get the size of the canvas and backend :\n","    c_size = canvas.size\n","    b_size = canvas._backend._physical_size\n","\n","    # If the GUI is displayed, c_size and b_size should be equals. If not,\n","    # and if the canvas is resizable, the canvas might have a different size\n","    # because it hasn't been updated. In that case, we force the canvas to have\n","    # the same size as the backend :\n","    if c_size != b_size:\n","        canvas.size = b_size\n","\n","    # Backup size / background color :\n","    backup_size = canvas.physical_size\n","    backup_bgcolor = canvas.bgcolor\n","\n","    # dpi checking :\n","    if print_size is None:\n","        logger.warning(\"dpi parameter is not active if `print_size` is None. \"\n","                       \"Use for example `print_size=(5, 5)`\")\n","\n","    # User select a desired print size with at a specific dpi :\n","    if print_size is not None:\n","        # Type checking :\n","        if not isinstance(print_size, (tuple, list)):\n","            raise TypeError(\"The print_size must either be a tuple or a list \"\n","                            \"describing the (width, height) of the\"\n","                            \" image in %s\" % unit)\n","        # Check print size :\n","        if not all([isinstance(k, (int, float)) for k in print_size]):\n","            raise TypeError(\"print_size must be a tuple describing the \"\n","                            \"(width, height) of the image in %s\" % unit)\n","\n","        print_size = np.asarray(print_size)\n","        # If the user select the auto-croping option, the canvas must be render\n","        # before :\n","        if autocrop:\n","            img = canvas.render()\n","            s_output = piccrop(img)[:, :, 0].shape\n","            logger.info(\"Image cropped to closest non-backround pixels\")\n","        else:\n","            s_output = b_size\n","        # Unit conversion :\n","        if unit == 'millimeter':\n","            mult = 1. / (10. * 2.54)\n","        elif unit == 'centimeter':\n","            mult = 1. / 2.54\n","        elif unit == 'pixel':\n","            mult = 1. / dpi\n","        elif unit == 'inch':\n","            mult = 1.\n","        else:\n","            raise ValueError(\"The unit must either be 'millimeter', \"\n","                             \"'centimeter', 'pixel' or 'inch' and not \" + unit)\n","        # Get the factor to apply to the canvas size. This factor is defined as\n","        # the mean required float to get either the desired width/height.\n","        # Note that the min or the max can also be used instead.\n","        factor = np.mean(print_size * dpi * mult / np.asarray(s_output))\n","\n","    # Multply the original canvas size :\n","    if factor is not None:\n","        # Get the new width and height :\n","        new_width = int(b_size[0] * factor)\n","        new_height = int(b_size[1] * factor)\n","        # Set it to the canvas, backend and the widget :\n","        canvas._backend._vispy_set_physical_size(new_width, new_height)\n","        canvas.size = (new_width, new_height)\n","        if widget is not None:\n","            widget.size = (new_width, new_height)\n","\n","    # Background color and transparency :\n","    if bgcolor is not None:\n","        canvas.bgcolor = color2vb(bgcolor, alpha=1.)\n","    if transparent:\n","        canvas.bgcolor = [0.] * 4\n","\n","    # Render the canvas :\n","    try:\n","        img = canvas.render(region=region)\n","    except:\n","        raise ValueError(\"Can not render the canvas. Try to decrease the \"\n","                         \"resolution\")\n","\n","    # Remove alpha for files that are not png or tiff :\n","    if os.path.splitext(filename)[1] not in ['.png', '.tiff']:\n","        img = img[..., 0:-1]\n","\n","    # Apply auto-cropping to the image :\n","    if autocrop:\n","        img = piccrop(img)\n","        logger.info(\"Image cropped to closest non-backround pixels\")\n","    # Save it :\n","    imsave(filename, img)\n","    px = tuple(img[:, :, 0].T.shape)\n","    logger.info(\"Image of size %rpx successfully saved (%s)\" % (px, filename))\n","\n","    # Set to the canvas it's previous size :\n","    canvas._backend._physical_size = backup_size\n","    canvas.size = backup_size\n","    canvas.bgcolor = backup_bgcolor\n","\n","\n","def write_fig_pyqt(self, filename):\n","    \"\"\"Export a GUI window as a figure.\n","\n","    Parameters\n","    ----------\n","    self : struct\n","        The self structure of the GUI window.\n","    filename : string\n","        The picture file name.\n","    \"\"\"\n","    from PyQt5 import QtWidgets, QtCore\n","\n","    # Screnshot function :\n","    def _take_screenshot():\n","        \"\"\"Take the screenshot.\"\"\"\n","        screen = QtWidgets.QApplication.primaryScreen()\n","        p = screen.grabWindow(0)\n","        p.save(filename)\n","        logger.info('Image successfully saved (%s)' % filename)\n","    # Take screenshot if filename :\n","    if filename:\n","        # Timer (avoid shooting the saving window)\n","        self.timerScreen = QtCore.QTimer()\n","        # self.timerScreen.setInterval(100)\n","        self.timerScreen.setSingleShot(True)\n","        self.timerScreen.timeout.connect(_take_screenshot)\n","        self.timerScreen.start(500)\n","        \n","def color2vb(color=None, default=(1., 1., 1.), length=1, alpha=1.0,\n","             faces_index=False):\n","    \"\"\"Turn into a RGBA compatible color format.\n","\n","    This function can tranform a tuple of RGB, a matplotlib color or an\n","    hexadecimal color into an array of RGBA colors.\n","\n","    Parameters\n","    ----------\n","    color : None/tuple/string | None\n","        The color to use. Can either be None, or a tuple (R, G, B),\n","        a matplotlib color or an hexadecimal color '#...'.\n","    default : tuple | (1,1,1)\n","        The default color to use instead.\n","    length : int | 1\n","        The length of the output array.\n","    alpha : float | 1\n","        The opacity (Last digit of the RGBA tuple).\n","    faces_index : bool | False\n","        Specify if the returned color have to be compatible with faces index\n","        (e.g a (n_color, 3, 4) array).\n","\n","    Return\n","    ------\n","    vcolor : array_like\n","        Array of RGBA colors of shape (length, 4).\n","    \"\"\"\n","    # Default or static color :\n","    if (color is None) or isinstance(color, (str, tuple, list, np.ndarray)):\n","        if color is None:  # Default\n","            coltuple = default\n","        elif isinstance(color, (tuple, list, np.ndarray)):  # Static\n","            color = np.squeeze(color).ravel()\n","            if len(color) == 4:\n","                alpha = color[-1]\n","                color = color[0:-1]\n","            coltuple = color\n","        elif isinstance(color, str) and (color[0] is not '#'):  # Matplotlib\n","            # Check if the name is in the Matplotlib database :\n","            if color in mplcol.cnames.keys():\n","                coltuple = mplcol.hex2color(mplcol.cnames[color])\n","            else:\n","                warn(\"The color name \" + color + \" is not in the matplotlib \"\n","                     \"database. Default color will be used instead.\")\n","                coltuple = default\n","        elif isinstance(color, str) and (color[0] is '#'):  # Hexadecimal\n","            try:\n","                coltuple = mplcol.hex2color(color)\n","            except:\n","                warn(\"The hexadecimal color \" + color + \" is not valid. \"\n","                     \"Default color will be used instead.\")\n","                coltuple = default\n","        # Set the color :\n","        vcolor = np.concatenate((np.array([list(coltuple)] * length),\n","                                 alpha * np.ones((length, 1),\n","                                                 dtype=np.float32)), axis=1)\n","\n","        # Faces index :\n","        if faces_index:\n","            vcolor = np.tile(vcolor[:, np.newaxis, :], (1, 3, 1))\n","\n","        return vcolor.astype(np.float32)\n","    else:\n","        raise ValueError(str(type(color)) + \" is not a recognized type of \"\n","                         \"color. Use None, tuple or string\")\n"],"execution_count":0,"outputs":[]}]}